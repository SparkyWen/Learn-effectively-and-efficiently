大家好,这里是AI大模型周报2024年1月的第三期。阿里巴巴的研究者推出MotionShop,能够将视频中的人物转换成3D形象。框架包括两个部分,一个是视频处理Pipeline,负责提取视频背景,一个是动作预测和渲染Pipeline,负责生成3D形象。上传一段15秒以内的视频,它会自动识别需要转换的人物,选择生成目标形象,而目前有四个可选项,等待大约10分钟就可以了。这个案例的效果还是可以的。但是我上传的这个武术视频,武术套路的视频,它生成的3D效果实在很奇怪就不播放了。南开大学腾讯ARC Lab和东京大学的研究者聚焦身份保真度ID Fidelity,推出个性化文生图方案Photomaker,分别将图像嵌入和文本嵌入放入多层感知机,也就是MLP,来形成堆叠的身份嵌入,Stacked ID Embedding,然后喂给所有交叉注意力层,将身份内容融合到扩散模型中。Photomaker支持修改主体特征,将画作转化成具有真实感的照片,以及融合多个身份。相较Dreambooth,Textual Inversion等同类方案,Photomaker的图像质量更高。Google Research的研究者推出文生图增强学习框架Parrot,结合文图相辅、艺术美学、人类偏好、图像情感等关于图像质量的考量,利用增强学习有效优化多轮奖励,并通过批量帕累托最优选择Batchwise Pareto Optimal Selection来平衡这些奖励,在贴合文本内容的同时全方位提高图像质量。特拉维夫大学的研究者推出个性化文生图方案POP,全称是Prompt-aligned Personalization,能够在图像内容贴合复杂文本提示词的同时兼顾图像风格的个性化。POP支持包含多个主体的图像生成,图像质量较高。加州大学的研究者面向自动化视频配音推出大规模数据集NF400K,包含42.5多万日语和英语的动画视频片段,在自动化配音之外还支持即时翻译、视频总结、类型主题风格分类等任务。华盛顿大学和微软研究者针对大模型推理成本问题推出Splitwise方案。大模型推理流程主要分两个阶段,即提示词计算Prompt Computation和双重输入Token Generation。前者是计算密集型的任务,后者是内存密集型的任务。Splitwise将这两个阶段分开,也就是Phase Splitting,放在不同的机器上,从而充分利用硬件,有效降低推理成本。AWS AI Labs和Amazon Web Services的研究者面向数据库的故障排除问题推出Panda框架,旨在为预训练大模型提供背景定位Context Grounding,从而生成更加有用和符合背景的故障排除意见。Panda主要由四个部分组成,分别是定位机制Grounding,为用户的问询提供必要的背景,还有验证机制Verification,来保证答案的正确性,以及可供机制Affordance,评估每条故障处理建议的影响,还有反馈机制Feedback,收集和存储大模型用作背景的反馈以提升生成质量。特拉维夫大学和Google Research的研究者发现,多语种指令微调有助于增强大语言模型的跨语言理解能力。不同于传统的需要大量特定语言数据的单语语言微调,研究者将一个较小的但是多样的多语种范例数据集融合到指令微调过程中,以更少的资源提升大模型的多语种能力。Google Research和特拉维夫大学的研究者为提升大语言模型的可解释性Interpretability,推出Patch Scopes框架,能够更好地检查语言模型的隐藏表征,也就是它的Hidden Representations,将模型的内部机制翻译成更加自然的语言格式,从而帮助提升模型的效率以及对其人类的价值观和伦理。MIT等研究者推出Find Function Interpretation and Description基准,对复杂神经网络的自动化解释方案进行评估。研究发现,用语言模型打造的自动化解释代理,简称AIA,有时是可以推理函数结构的。然而,基于语言模型的描述在把握全局函数行为的同时,也会忽略局部细节。True AI聚焦AI代理协作,旨在帮助AIA agents各司其职共享目标,就像默契的船员那样协同互动,共同完成复杂的任务。基于网络海量数据训练的大语言模型可能涉及敏感隐私数据带来法律或伦理问题,而遗忘学习或者反学习Unlearning有助于让模型遗忘训练数据中的信息,在训练完成后有效保护隐私数据。True Food豆腐,它的全称是Task of Fictitious Unlearning,虚构反学习任务,它附带一个包含遗忘级的数据集Forget Set,旨在通过遗忘和保留虚构信息等步骤实现Unlearning。Meta AI面向代码推理理解和执行推出新的基准Crooksyval,Code Reasoning Understanding and Execution Evaluation,它主要包含两项任务,分别是输出预测,由Crooksyval O,也就是Output,评估代码执行结果,以及输入预测,由Crooksyval I,也就是Input,来评估代码推理和理解能力,可以检查代码语言模型对简单的Python程序执行行为的理解能力。研究者用Crooksyval基准评估了20个代码模型,发现最近一些在Human Eval得分较高的模型在Crooksyval并没有显出同样的进步。斯坦福大学和VMware Research的研究者推出代码生成验证工具Clover,将代码核查问题,也就是Correctness Checking,变成一致性核查问题,Consistency Checking,核查代码文档字符串以及注解的一致性。实验发现Clover核查器对正确示例的接受率达了87%,对错误示例的拒绝率达了100%。Gateway开源方案提供一个普遍适用的API,能够无缝连接各种模型,跨越多个API Keys和提供商散发用户请求。如果某个提供商或者模型出现错误,Gateway就会无缝切换到其他备选项,负能持续可靠的AI开发流程。DeepSeek AI以及北大精华南京大学的研究者推出DeepSeek MOE专家模型,表现堪比70亿参数的Lama2,特别在数学和代码能力方面相较Lama表现明显更好,而计算量却只有它的40%。谷歌的研究者面向医患对话AI诊断推出基于大语言模型的AI系统AMI,Articulate Medical Intelligence Explorer,通过模拟环境和自动反馈机制对各类疾病情况、背景等进行学习。随机双盲实验发现,相较初级护理医师,AMI它在管理计划、诊断准确度、沟通技巧和同心心方面表现更好。但需要注意的是,研究实验有自身的局限性,投入实际应用还需要更多研究。1月16日,Stability AI面向代码编程推出大模型Stable Code,能够理解处理18种编程语言,相较71参数的Code Llama,31参数的Stable Code表现相当,而且对硬件要求也不高,使用普通笔记本电脑也能运行。1月16日,Mnemax全量发布大语言模型ABAB6,ABAB6,称是国内首个千亿参数以上的基于MOE,Mixture of Experts架构的大语言模型,在遵守用户指令以及英文中文综合能力方面,ABAB6它表现超过GPT3.5。蚂蚁开源计算法Lookahead推理加速框架能够做到效果无损及差即用,支持包括Lama,OPT,Bloom,BaiChuan,ChatGLM和千问等一系列大模型。Lookahead已经在蚂蚁大量场景进行落地,实际获得2.66到6.26倍的加速比,大幅降低了推理耗时。这期节目就到这里,Thanks for listening!

[AMIE] https://arxiv.org/abs/2401.05654 
[Anim-400K] https://arxiv.org/abs/2401.05314
[Clover] https://arxiv.org/abs/2310.17807
[CrewAI] https://github.com/joaomdmoura/crewAI
[CRUXEval] https://arxiv.org/abs/2401.03065
[DeepSeekMoE] https://arxiv.org/pdf/2401.06066.pdf
[FIND] https://arxiv.org/abs/2309.03886
[Gateway] https://github.com/Portkey-AI/gateway
[Lookahead] https://arxiv.org/abs/2312.12728
[Minimax] https://api.minimax.chat
[Motionshop] https://aigc3d.github.io/motionshop
[Multilingual Tuning] https://arxiv.org/abs/2401.01854
[PALP] https://arxiv.org/abs/2401.06105
[Panda] https://www.amazon.science/publications/panda-performance-debugging-for-databases-using-llm-agents
[Parrot] https://arxiv.org/abs/2401.05675
[Patchscopes] https://arxiv.org/abs/2401.06102
[PhotoMaker] https://arxiv.org/abs/2312.04461
[Splitwise] https://arxiv.org/abs/2311.18677
[TOFU] https://arxiv.org/abs/2401.06121
