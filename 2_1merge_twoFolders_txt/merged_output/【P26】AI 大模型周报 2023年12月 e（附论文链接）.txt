大家好,这里是AI大模型周报,2023年12月的第五季,也是今年的最后一季。英国萨里大学和北京邮电大学的研究者推出AI系统DreamWire,帮助用户创作多视角线条艺术,Multiview Wire Art,也就是中间一团线条,但会在不同的角度展现出不同的图像。用户输入文本提示词或者涂鸦的图像,DreamWire就能生成对应的多视角线条艺术。华为诺亚方舟实验室英国伦敦大学学院以及牛津大学的研究者推出可微调的通用型代理框架Pangu Agent,采用结构化推理的方式来支持Agent的内部思考流程,会结合初始状态,根据提示执行动作,然后观察接下来的状态以及动作反馈,生成的轨迹用来进行大模型微调。通过纳入有组织的推理,Organized Reasoning和先前累积的推理结构的相关知识,Prior Knowledge,AI Agent就可以大幅提升性能还有灵活度。另外该框架支持多个代理的环境,Multi-Agent Environment,不同的Agents可以在同一个任务中相互协作或者独立工作。华为云AI编程大模型CodeArt Snap开启公测,基于盘古大模型研发,提供智能生成、智能问答、智能协同等核心能力,可以帮助开发者在多类研发场景中提升效率,包括代码开发、代码优化、需求管理分析等等。12月28日,百度发布CodeMate Outerwork,支持系统化处理复杂的研发任务。开发者仅需明确目标和意图,Outerwork就能深度解读代码库,制定执行计划并智能生成代码。另外,百度首席技术官王海峰宣布文心一言用户规模突破1亿人。阿里巴巴研究者面向文生图和可控图像合成领域推出SC Edit,生成式微调框架,能够高效出色地完成任务,支持结合多个条件生成可以调节的内容。同时大幅减少训练参数、内存使用和算力开支。SC Edit的SC代表Skip Connection,跳跃连接,是指将输入直接连接到输出,让信息在网络的不同层之间跳跃传递。比较发现SC Edit的图像质量更高,对不同风格的学习和掌握较好。阿里巴巴等研究者推出i2v Genre XL,i2v就是Image to Video图像转视频,利用级联扩散模型基于图像合成高质量的视频。支持的图像视频类型包括艺术、人物、动物、科技等等。从AI视频生成平台Runway的Gen2以及Picker Labs的比较发现,i2v Genre XL丢失了输入图像的一些细节,也就是它的ID Preservation身份保持方面还有待提升,但是展现出更加真实和多样的动作,比如A Flying Dog一只飞行的小狗,翅膀的生动效果。香港中文大学上海AI实验室和深圳大数据研究院的研究者推出M-FEON开源工具包,用于生成音频、音乐和语音。相较同类开源工具,M-FEON的优势在于框架统一,对新手友好,并提供可视化教学,包括演示生成式模型的内部工作机制。香港中文大学商汤等研究者推出自动驾驶框架LM Drive,利用大语言模型负能闭环端到端的自动驾驶。LM Drive能够处理并融合多模态传感器数据以及自然语言指令,助力富有挑战性的驾驶场景。腾讯的研究者推出App Agent,这是一个基于大模型的旨在运行智能手机应用的多模态代理框架。App Agent通过自主探索或者观察人类演示来学习使用新的应用,进而形成一个知识库,支持代理跨越不同的应用执行复杂的任务。App Agent可以模仿点击和滑动屏幕等交互动作,所以无需系统接入也能运行手机应用,进而适用于更加多样的应用,覆盖社交媒体、邮件、地图、购物、图像编辑工具等等。谷歌等研究者面向实时大规模勘测领域推出Smurf,全称是Streamable Memory Efficient Radiance Fields,在线高内存效率辐射场。它能够对300平方米的空间进行精确的视角合成,支持网页浏览器的六自由度的3D导航,并在智能手机或电脑上进行60帧每秒的实时渲染。相较3D高斯渐瘦,就是3DGX,Smurf它能够更好地复现微小的几何形状、纹理以及图像效果。Google Research推出视频生成大模型Video Poet,支持文本或图片生成视频,支持视频风格渲染、内容修复和尺寸扩展,根据视频生成音频等等。我们在上一期节目有专门介绍这个模型,欢迎大家参考。Microsoft Research的研究者推出大模型赋能的数据探索系统Inside Pilot,旨在简化数据探索的流程,也就是Data Exploration,也就是对数据进行初步了解和分析的过程,通常包括数据清洗、数据可视化和统计分析等步骤。用户只需用自然语言提出问题,Inside Pilot就会和大语言模型协作展开数据分析并生成洞见。微软亚洲研究院的研究者推出Prompt Bench,这是一个大模型评估集成库,由若干关键部分组成,包括提示词建设、提示词工程、数据集和模型加载、对抗性提示攻击、动态评估协议以及分析工具。研究者可以轻松使用和扩展这些部分,研究新的大模型基准、部署下游应用或者设计新的评估协议。Meta的研究者面向视频编辑推出Theory,全称是Fast Parallelized Instruction Guided Video to Video Synthesis,快速并行的由指示引导的视频合成视频的方案。给出要编辑的视频以及编辑指令,Theory就能在保持时序一致、内容忠实的前提下实现精准的合成编辑,只需14秒就能生成120帧的分辨率512x384的视频。Theory能够处理多种编辑指令,包括主题切换、风格转换、局部修饰、特征替换等等。相较Token Flow、Gen1等视频编辑框架,Theory的表现更加出色。南加州大学和字节跳动研究者推出条件扩散模型Diff Portrait 3D,能够以最少一张的尽可能少的肖像照合成真实的人物身份和面部表情一致的3D新视角,无需微调。相较0813等同类框架,Diff Portrait 3D的表现更优。Open Drive Lab等的研究者推出自动驾驶代理DriveLM,是有点眼熟,前面刚说了一个LM Drive。那这个DriveLM可以通过图形视觉问答,也就是Graph VQA,来将观察、预测和规划的问答对,Question Answer Pairs,将这些问答对串联起来,从而模拟人类驾驶者的推理流程,每个环节的背景都以前面的问答为基础,生成人类用户更容易理解的输出。清华大学和智博AI的研究者推出180亿参数视觉语言模型Cock Agent,能够很好地理解和规划GUI,也就是图形用户界面,来支持1120x1120分辨率的输入,因而可以识别界面上微小的元素和文本。Cock Agent具备通用的跨模态任务处理能力,为创建GUI Agents解决了训练数据问题,且较好的找到了输入图像分辨率与需要消耗的算力这两者之间的平衡。12月27日,OPPO宣布NDC大模型Alice GPT全新升级,将分成1800亿参数、700亿参数和70亿参数三种体量,支持端元协同部署,根据不同的场景和用户需求实现智能调度。Alice GPT的知识、记忆和工具能力将为小步助手赋能,提供个性定制的智慧服务。同时在端侧应用70亿参数的大模型让内容摘要2000字的首次生成时间只需2.9秒,比行业标准要快2.5倍。文本之外,Alice GPT也将支持全面的语音和视觉体验。昆仑万维AI Agents开发平台天工Sky Agents开放测试,平台基于天工大模型打造,具备感知、决策和执行能力,用户可以通过自然语言创建自己的AI助理。12月26日,Paker团队宣布Paker 1.05网页端访问权限面向所有用户开放,我们星期天刚好有介绍一系列文本转视频的工具,其中包括Paker Labs。现在登录paker.art,输入提示词即可生成3秒长的视频片段,支持re-prompt,就是修改提示词,支持编辑视频局部内容,支持调整画布的尺寸等等。感兴趣的同学可以去看一看那期节目。OpenAI CEO Sam Altman发推文征求网友意见,他问2024年你最期待OpenAI能够创建或者完善什么?其中呼声最高的条目包括AG

[DreamWire] https://arxiv.org/abs/2311.15421
[Pangu Agent] https://arxiv.org/abs/2312.14878
[CodeArts Snap] https://www.huaweicloud.com/product/codeartside/snap.html
[SCEdit] https://arxiv.org/abs/2312.11392
[I2VGen-XL] https://arxiv.org/abs/2311.04145
[Amphion] https://arxiv.org/abs/2312.09911
[LMDrive] https://arxiv.org/abs/2312.07488v2
[AppAgent] https://arxiv.org/abs/2312.13771
[SkyAgents] https://model-platform.tiangong.cn
[SMERF] https://arxiv.org/abs/2312.07541
[VideoPoet] https://sites.research.google/videopoet
[InsightPilot] https://www.microsoft.com/en-us/research/publication/insightpilot-an-llm-empowered-automated-data-exploration-system
[PromptBench] https://arxiv.org/abs/2312.07910v1
[Fairy] https://arxiv.org/abs/2312.13834
[DiffPortrait3D] https://arxiv.org/abs/2312.13016
[DriveLM] https://arxiv.org/abs/2312.14150v1
[CogAgent] https://arxiv.org/abs/2312.08914v1
