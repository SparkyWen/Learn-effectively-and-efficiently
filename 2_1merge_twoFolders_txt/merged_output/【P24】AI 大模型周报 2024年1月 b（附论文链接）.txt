大家好,这里是AI大模型周报2024年1月的第二期
英伟达宣布为生成式AI虚拟形象开发套件Ace推出微服务
Ace代表Avatar Cloud Engine
进一步帮助开发者将领先的生成式AI模型能力
融合到游戏或者应用的数字形象中
比如AI模型NVIDIA Omniverse Audio Deface
可以根据音频生成丰富的面部表情和对应的口型
NVIDIA REVV自动语音识别
则可以实现多余种交互和翻译
生成式AI让每次对话的内容都不同
使用Ace的开发者包括米哈尤、网易游戏、腾讯、育碧、InWorld等等
百川智能发布角色大模型百川NPC
只需文字描述即可生成角色智能体
模型在对话能力、角色一致性、扮演吸引力方面
相较通用模型有明显的优势
能够精确理解对话语境
以更加贴合角色性格的方式进行交流和互动
用户可以和虚拟的历史人物、影视人物等对话
也可以打造自己的虚拟角色
这里是我设置的Aki喜欢学习外语
然后问她会哪些语言
她就自由发挥说会九种语言
虽然其实还是只能用中文和英文与她交谈
1月9日科大迅飞发布基于迅飞星火认知大模型打造的智能数字员工
有三种类型包括管理数字员工、营销数字员工和办公数字员工
丁丁也在1月9日发布AI助理产品
用户可以一键创建个性化AI助理
企业也可以创建招聘AI助理、财务AI助理、报表AI助理等等
AI助理可以借助开放接口与视频、资讯、电商等第三方App连接
美帝集团和华东师范大学的研究者推出
小语言模型复能的多模态视觉语言助手Lavafy
展示了只有27亿参数的小模型
也可以有效进行复杂的多模态对话
其视觉理解、推理和基于知识的感知能力值得称赞
在巨声代理Embodied Agents等需要实施交互的应用场景中颇有潜力
Google DeepMind推出巨声基础模型AutoRT
支持机器人代理的大规模部署
模型利用视觉语言模型VLM来理解场景和定位
然后大语言模型根据VLM的描述提出多样化的新指令
然后再由另一个大模型提出批评建议
从而让指令更加安全可执行
由多个机器人通过自行生成的任务收集数据
完善应对各类未知环境的能力
新加坡出厂公司面向开放世界游戏推出
角色扮演语言代理LARP
旨在打造能够灵活适应复杂环境
具备长期记忆来确保行为一致的代理
LARP主要由三个部分组成
一是认知架构
包含记忆处理和决策助手
二是环境交互模块
有以反馈为驱动的可学习和动作空间
三是一套后处理方法
A post-processing method
主要对其不同的人格
LARP框架能够提升用户和代理之间的互动
增强开放世界背景的游戏体验
华为诺亚方舟实验室的研究者
针对大模型当前的局限问题
推出模型架构盘古派
通过为Transformer框架引入基于序列的激活函数
(Series-based activation functions)
以及增强捷径(Augmented architecture)
来强化模型的非线性结构(The non-linearity)
从而减轻功能崩溃的问题
与领先的70亿参数开编模型比较
盘古派表现不俗
团队还将70亿参数的盘古派
部署到金融和法律领域
开发云山大模型
其表现超过其他规模相间的模型
UCLA的研究者推出大模型微调方案SPAN
(Self-play fine-tuning)
从监督微调模型出发
利用自我对局的机制(a self-play mechanism)
并且让大模型从之前的迭代中生成自己的训练数据
无需额外的人工注视的数据
也可以显著提升大模型的能力
效果可见推理、数学、编码、人文、协作等各方面
Salesforce Research等研究者面向多模态条件下的
可控视频生成与编辑
推出Moonshot
可同时以图像和文本的多模态输入为条件
该模型以MVB(Multi-model Video Block)
多模态视频块为核心组件
由传统的时空层和结偶的交叉注意力层组成
模型架构可以有选择的融合ControlNet
预训练图像模块
从而省去额外的训练
实验发现Moonshot在视觉效果和时序一致性方面的表现更好
德克萨斯大学Austen分校和MetaGenAI的研究者面向
视频生成视频
推出FlowVid
可以根据一段输入视频以及提示词
通过估算和修正输入视频的光流
就是它的Optical Flow
合成连贯的视频
FlowVid适用于视频风格转化
替换主体
或者本地编辑
相较Rewender
还有TokenFlow等其他视频生成视频的模型
FlowVid的提示词贴合度和整体视频的质量更高
惠琳顿维多利亚大学和英伟大研究者
面向视频生成控制
推出TrailBlazer算法
基于一个预训练的T2V也就是Taxed Video模型打造
直接利用边界框Bounding Box
来引导内容主体
无需神经网络训练微调等等
另外团队引入关键帧的概念
Key Framing
让移动的边界框以及对应的提示词
能够同时引导主体轨迹和整体内容
AMIG计算机科学与人工智能实验室
就语言模型的视觉能力进行研究
包括大模型编写代码
渲染出复杂视觉概念的能力
从代码中识别视觉概念的能力
根据文本反馈纠正渲染代码的能力
以及大模型是否能够生成数据
来训练能够对自然图像进行语意判断的高性能视觉系统
为此团队收集了一个视觉类别数据集
包括形状、物体和场景描述
让大模型按照文本到代码到图像的顺序生成图像
研究发现大语言模型具备比较全面的视觉能力
并且模型自己的文本反馈有助于增强模型的视觉能力
JB Morgan AR Research面向企业文件理解推出Dark L-Alarm
可以看作对传统的视觉文件推离大模型的轻量型扩展
同时考虑文本语意和空间布局
不同于现有的多模态大模型Dark L-Alarm
绕开昂贵的图像变码器
而只凭借边界框的信息来纳入空间布局结构
同时将经典Transformers的注意力机制分解成一系列独立的矩阵
并且设计一个预训练目标学习填充文本
从而处理文件中常见的不规则布局和意志内容
Ellenoys大学香檳分校的研究者提出
如果大模型是魔法师,代码就是魔杖
指出将代码融合到大模型的训练数据中有诸多好处
在提升大模型生成代码的能力之外
还有助于
1.提升大模型的推理能力
2.生成有结构精准的中间步骤
通过函数调用连接到外部执行端口
3.利用代码编译和执行环境提供多样化的反馈
提升模型性能
4.更好地理解指令、结构目标、规划行动并且执行等等
这是代码对智能代理大模型的复能作用的全景图
感兴趣的同学可以参考原文
开源AI框架GPT Engineer利用GPT-4复能软件开发流程
将自然语言表述的软件要求准确地转化成可以执行的代码
无需人工编程
香港大学等的研究者推出83亿参数基础模型LAMA PRO
基于70亿参数的LAMA II打造
通过扩展Transformer Blocks
并且只用新的语料库微调扩展的Blocks
从而在不影响现有知识的情况下有效提升模型的知识
LAMA PRO尤其擅长通用型任务、编程和数学领域
与其指令遵循版LAMA PRO INSTRUCT一起
在多项基础的表现超过LAMA家族的现有开源模型
谷歌研究者面向提升模型组合效率推出COM
Composition to Augment Language Models
通过交叉注意力来组合模型表示
从而重复利用现有的大模型
实现在多样的领域和场景中的新能力
问答网站Cora获得Anderson Horowitz的7500万美元融资
用来发展其AI聊天平台POW
POW集成了一系列文本和图像AI模型
包括ChatGPT, Dolly3, Cloud2, StableDiffusion, LAMA等等
为创作者提供丰富的工具和空间
OpenAI GPT Store本周正式启动
GPT的开发者需要了解OpenAI更新的使用规则
保证GPT回归才能登陆商店
另外用户需要验证身份
以公开的方式发布自己的GPT
我们来看一下它主要有
Featured, Trending, ChatGPT团队的一些GPT
图像,写作,工作效率,分析,研究
还有编程,教育,生活方式等等
这期节目就到这里,Thanks for listening

[Baichuan-NPC] https://npc.baichuan-ai.com/index
[LLaVA-ϕ] https://arxiv.org/abs/2401.02330
[AutoRT] https://auto-rt.github.io
[LARP] https://arxiv.org/abs/2312.17653
[PanGu-π] https://arxiv.org/abs/2312.17276
[SPIN] https://arxiv.org/abs/2401.01335
[Moonshot] https://arxiv.org/abs/2401.01827
[FlowVid] https://arxiv.org/abs/2312.17681
[TrailBlazer] https://arxiv.org/abs/2401.00896
[Vision Check-up] https://arxiv.org/abs/2401.01862
[DocLLM] https://arxiv.org/abs/2401.00908
[Code Is the Wand] https://arxiv.org/abs/2401.00812
[GPT-Engineer] https://github.com/gpt-engineer-org/gpt-engineer
[LLaMA Pro] https://arxiv.org/abs/2401.02415
[CALM] https://arxiv.org/abs/2401.02412
