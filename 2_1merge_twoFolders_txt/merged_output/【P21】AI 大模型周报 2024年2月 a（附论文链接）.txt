大家好,这里是AI大模型周报2024年2月的第一季。普林斯顿大学的研究者推出大模型推理加速框架Medusa,通过增加解码头,也就是Decoding Head挫折Medusa Heads,来实现多个后续单元的并行预测,每个头都会为对应的位置生成若干预测,这些预测会集合成候选结果,采用Tree Attention的机制来得到最优的候选片段。实验发现Medusa能够为大模型推理加速2.2倍到3.6倍。西北工业大学和自体跳动研究者推出Stream Voice声音转化模型,采用识别合成框架,这个Recognition Synthesis,融合一个上下文感知语言模型,Context Aware Language Model,还有一个声音预测器,Acoustic Predictor,来实现零样本的实时的几乎没有延迟的高质量声音转化,那连这个论文都在暗示江户川柯南的变声器。心内机,苦头心内机。浙江大学的研究者推出网页代理Web Voyager,基于多模态大模型能够与真实世界的网页交互,端到端完成用户指令。评估发现Web Voyager的任务成功率达到55.7%,明显超过GPT-4,在实际应用中很有潜力。摩纳什大学的研究者推出不确定性感知语言代理UALA,利用Uncertainty Quantification,也就是不确定性量化,来进行代理与外部世界之间的协调。相较React等方法,UALA的表现更好,对外部世界的依赖也更少。依然是摩纳什大学的研究者推出大模型赋能的虚拟助手GPT Voice Tester,能够根据手机用户的任务需求,将复杂的任务分解成较小的可以管理的提示,反复提示大模型根据当前的UI信息,也就是用户界面信息,来预测并执行屏幕操作,从而达成任务。执行信息会存储起来,方便后续执行相似的任务。爱丁堡大学的研究者推出Serverless LLM,本地增强的无服务剂推理系统,利用GPU服务器上可用的存储和内存设备的容量和带宽,减少远程检查点下载,实现高效的检查点加载。实验发现在运行OPT模型跨数据集推理方面,Serverless LLM的延迟改善超过先进系统的10到200倍。中山大学和腾讯AI Lab的研究者提出大模型知识融合的概念,Knowledge Fusion for LLMs。不同于权重合并等常规的融合方法,Fuse LLM通过概率建模,Probabilistic Modeling,来融合现有的多个异构大模型的能力,及各家之所长,转化成一个大模型。在推理、常识、代码生成等各类任务中超越原模型。华盛顿大学的研究者针对AI幻觉问题提出自动细粒度幻觉检测任务,分析发现ChatGPT和Lama2Chat的输出分别有60%和75%的部分包含这样那样的幻觉问题。为此,团队利用高质量合成数据训练了检索增强语言模型Fava,FAVA,全称是Fact Verification with Augmentation,旨在检测并更正细粒度幻觉问题。评估显示,Fava在检测细粒度幻觉方面的表现明显优于ChatGPT。EGH Zurich,苏黎世联邦理工学院的研究者面向RLF,也就是人类反馈增强学习,推出WestFM次训练策略,旨在提升奖励模型的质量。WestFM通过选择问询回复中最好的和最坏的候选项来生成合成偏好数据,就是Synthetic Preference Data,并融合到训练数据集,它对奖励模型的增强效果与融合等量的人类偏好数据是相当的。EGH Zurich和微软的研究者推出大模型稀疏化方案SliceGPT,就是一个Sparsification Scheme,它通过删除权重矩阵中的行和列来降低网络的进入维度,同时保持模型性能。实验发现SliceGPT可以为661参数的OPT,710参数的Lama2和Phi2移除多达25%的模型参数,包括Embeddings,同时高度保持密集模型的零样本任务性能,分别达到99%,99%和90%。经过切片的模型,也就是Sliced Models,能够在更少的GPU上更快地运行,而且无需额外的代码优化。University of Amsterdam的研究者面向光化学和光催化实验推出自主化学合成机器人Robochem,对光催化实验进行自主优化、增强和扩展。平台及软件和硬件于一体,帮助没有编程和机器学习经验的化学家轻松监测、分析和改善光催化反应,有效提升总体反应收率和时空产率。1月30日,科大讯飞正式发布讯飞星火认知大模型3.5版本,在文本生成、逻辑推理、知识问答等7个方面进行全面升级。其中语言理解、数学能力超过GPT-4 Turbo,而代码能力达到GPT-4 Turbo的96%,多模态理解达到GPT-4 Vision的91%。阿里云发布新升级的通义千问视觉语言大模型千问VLmax,整体能力媲美甚至超越OpenAI的GPT-4V和谷歌的Gemini。谷歌推出视频生成模型Lumiere,使用名为Space Time Unit的扩散模型一次构建整个视频,更好地实现全局的时空一致性。Lumiere支持文本或图像生成视频,生成特定风格的视频,生成动态照片以及编辑视频内容等等。我们在上一期节目有专门介绍,感兴趣的同学请参考。百川智能正式发布千亿参数大模型百川3,在多个权威通用能力测评中展现出出色的能力,尤其在中文任务方面超越GPT-4。腾讯发布2024数字科技前沿应用趋势报告,预测数字科技未来发展趋势和应用前景。报告指出,高性能计算、量子计算、云计算和边缘计算四大计算融会贯通,中催生全新的计算范式。通用人工智能渐行渐进,大模型走向多模态。AI智能体,也就是Agent,有望成为下一代平台。学习节目就到这里,前面提到的论文请参考视频下方的简介部分的链接。Thank you for listening!

[Baichuan3] https://www.baichuan-ai.com/home
[FAVA] https://arxiv.org/abs/2401.06855
[GPTVoiceTasker] https://arxiv.org/abs/2401.14268
[FuseLLM] https://arxiv.org/abs/2401.10491
[Lumiere] https://lumiere-video.github.io
[Lumiere专题介绍] AI视频生成：Lumiere（超越 Runway 和 Pika）_哔哩哔哩_bilibili
[MEDUSA] https://arxiv.org/abs/2401.10774
[Qwen-VL] https://github.com/QwenLM/Qwen-VL
[RoboChem] https://www.science.org/doi/10.1126/science.adj1817
[ServerlessLLM] https://arxiv.org/abs/2401.14351
[SliceGPT] https://arxiv.org/pdf/2401.15024.pdf
[StreamVoice] https://arxiv.org/abs/2401.11053
[UALA] https://arxiv.org/abs/2401.14016
[WebVoyager] https://arxiv.org/abs/2401.13919
[West-of-N] https://arxiv.org/abs/2401.12086
