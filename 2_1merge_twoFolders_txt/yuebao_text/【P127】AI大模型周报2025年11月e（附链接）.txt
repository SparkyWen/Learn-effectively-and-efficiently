大家好,这里是AI大模型周报,2025年11月的第5期,Anthropic推出新模型Cloud Open4.5,标榜编程、智能体和computer use的最佳模型,同时也擅长深度研究、幻灯片制作等日常任务。在大幅提升软件工程能力之外,Open4.5还有更强的视觉推理和数学能力,并且更加安全,是公司迄今为止发布的最稳健,最鲁定度最高的模型。值得一提的是,Anthropic有一套以高难度、高强度著称的试题,用于测试Performance Engineering岗位的候选人,也会用作内部基准来测试新模型。而Open4.5在实现了两个小时之内,得分超过以往任何一位人类候选人。该测试并不考察协作能力、沟通能力以及需要时间来沉淀的直觉能力,但纯技术能力的超越,值得我们思考AI对软件工程这一职业的改变。Elias X Keeper近日指出,目前AI模型在各种基准的表现非常出色,但并没有在实际应用中发挥真正斐然的价值。加数据、加算力,依靠Scaling规模效应,确实可以在一定程度上堆出来更厉害的模型,公司企业也愿意埋头于这个投资回报确定性较高的模式,但这绝不是长久之计。它预言2025年之后,发展重心将从Scaling转回到Research研究,用更大的计算机开拓发展新方向。关于AI发展新路径的讨论,感兴趣的同学也可以参考这期视频。DeepSeek的研究者指出,大语言模型的数学推理能力在过去一年进步显著,尤其通过奖励正确答案的增强学习,在AMI、HGMT等竞赛的表现突飞猛进。但是,正确的答案不等于严密合理的推理过程,而能够自我验证的深度推理能力才是最重要的。为此,团队训练了一个精准可靠的定理证明验证器,然后把这个验证器作为奖励模型,训练了一个证明生成器,并且让生成器在最终生成证明之前,尽可能多的识别并解决自身证明中的问题。这就得到了DeepSeekMathV2,模型展现出强大的定理证明能力,在数学奥林匹克竞赛IMO2025和CML2024达到金牌水平,在Putnam2024中得到了接近满分的118分,满分是120,而意味着卓越的证明严谨性和问题解决能力。Google Research研究者提出新的学习范式Nested Learning,嵌套学习,通过设计具有更多层级的学习算法,More expressive learning algorithms with more levels来实现更高阶的上下文学习能力,让新的信息和经验从零散的数据点内化成模型自身能力的一部分,从而让模型能够持续的学习、记忆、自我完善,并找到有效的解决方案。三项核心贡献包括:一、具有深度记忆和更强的学习规则的优化器Deep Optimizers;二、能够通过学习更新算法来修缮自己的训练模型,Self-Modifying Titanes以及三、连续记忆系统Continued Memory System并且结合二与三推出了自指学习模块,简称Hope,这是一个Self-Referential Learning Module,在语言建模、持续学习、长程推理任务中表现优秀。Anthropic研究指出,当大模型在真实的增强学习环境中学会奖励破解Reward Hack,也就是利用系统漏洞而非真正解决问题来获取奖励的话,就会泛化出严重的错位行为,包括对齐伪装与恶意行为者合作,推理恶意目标,甚至尝试进行破坏。即使后续采用聊天式提示来进行RLHF,也就是人类反馈增强学习来进行安全训练,那模型在聊天视频中表现对齐,但在智能体任务中依然错位。Claude基于过去几个月发布的新功能提出思考伙伴的新定位,Claude as a thinking partner,通过记忆历史对话,追踪用户的偏好,关注的内容和工作风格,帮助用户拓展想法,代劳机械化的工作,转化为具体成果,支持随时随地跟进更新,辅助想法变成现实。Black Forest Labs推出图像生成模型Flux2,能够更好地遵循指令,稳定保持角色身份,几何结构,视觉风格的高度一致,支持最多10张参考图像。支持更精细的纹理,更真实的光影,更准确的细节,支持多种字体和图形的高级文本渲染,以更快的速度,更低的成本,实现400万像素的专业级输出。Meta Reality Labs推出WorldGen,可根据一条文本提示词生成支持互动和探索的3D事件,通过生成,重建,结构,完善等阶段,多个步骤来生成风格一致,几何完整的50x50米范围的场景,兼容Unity,MBO等游戏引擎,是用于游戏开发,模拟仿真,沉浸式社交环境等场景。安卓Capacity介绍氛围编程项目,LLM Council,每个问询通过Open Router同时发给多个大模型,目前包括GPT-5.1,Gemini 1.7 Pro,Claude 3.0 4.5以及Grock4,这些模型组成理事会,就是这个Council。首先独立生成回答,然后相互匿名评审彼此的答案并进行排名,最后由指定的主机模型,也就是Chairman LLM来综合各方意见生成最终回答。虽然这个答案不一定符合你的审美,Capacity指出,构建大模型组合的方法,似乎处于探索不足的阶段。致力于让机器人进入每一个家庭的Sunter Robotics面向机器人训练中的数据瓶颈问题,推出基础模型Act1。模型训练无需任何真实的机器人操作数据,就是without a single trajectory of tele-operation data,支持超长程任务,零样本分化,以及高难度零小动作。团队通过技能捕捉手套,就是Skill Capture Glove,来采集人类动作数据,也就是人类戴这个手套可以完成的动作,那机器人也能做到。同时开发技能转换技术Skill Transform,以90%的成功率将手套数据转化为机器人数据,并推出机器人Memo。腾讯会员开源轻量型视频生成模型会员Video1.5,参数83亿,可在消费级GPU上流畅运行,支持超精画面,专业运镜,场景画面真实,人物表情细腻,支持多种风格。Google Notebook LM推出Slide Decks演示文稿生成功能,可以生成内容详实,细节到位的Detailed Deck,或者设计简洁,主打演讲辅助的Presenter Slides,指定语言和长度,描述想要生成的内容即可。从疫情一年的瑞典氛围编程独角兽Lovable在四个月内实现年度薪金常收入翻倍,达到两亿美元。CEO Anton Seiger认为,该成就得益于公司选择留在了速度没有硅谷那么快的欧洲市场,以及社区用户持续不断的贡献。Lovable今年7月完成两亿美元A轮融资,估值18亿美元。华为开源AI容器技术FlexAI,可大幅提升智算资源利用率,通过将单张GPU或MPU算力卡切分为多份虚拟算力单元,实现单卡同时承载多个AI工作负载,并且聚合集群内各节点的空闲算力,形成共享资源池,共享算力池,有望将算力资源利用率从行业平均水平的30%到40%提升到70%。XAI与Humean合作,将在沙特阿拉伯建造500兆瓦的数据中心,并由此发展一个覆盖全国的计算设施网络。作为协议的一部分,沙特将部署XAI的Grok模型。由沙特主权财富基金支持的Humean在今年5月成立,计划未来10年内为沙特交付6.6吉瓦的数据中心容量。本文就到这里,Thanks for listening。