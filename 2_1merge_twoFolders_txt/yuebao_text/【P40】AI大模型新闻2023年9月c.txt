大家好,这里是AI大模型周报2023年9月的第三期。英伟达同Meta,Cohear等头部公司合作,旨在加速优化大模型推理能力,近期将发布TensorRT-LLM开源软件,通过装量并行动态P处理等方式,实现快速定制优化策略,在H100上以峰值性能Peak Performance运行大模型。这里说下装量并行是指将单个数学运算拆分到不同的GPU上运行,动态P处理是指优化调度技术,能够将大模型的GPU请求吞吐量减半,增加GPU的利用效率,降低TCO总拥有成本。以Llama2为例,经过TensorRT-LLM优化的H100推理速度是A100的4.6倍。微软研究人员推出代码生成模型Phi-1的迭代版Phi-1.5,而用在ChatGPT创建的教科书式合成数据进行训练。Phi-1.5它的参数仅10亿,只用8个A100 GPU训练了两周时间,就达到堪比参数百亿甚至上千亿的模型的能力,大幅降低训练门槛和成本,有望实现更加去中心化,更加民主化的AI研发。腾讯健康公布医疗大模型以及药物发现平台云深iDrug。医疗大模型基于混元大模型打造,产品覆盖智能问答,家庭医生助手,数字医疗影像平台等场景,可嵌入医疗环节全流程,提升医疗服务水平和质量。上海仁济医院运用医疗大模型打造虚拟形象小微护士,聚焦互联网医院式老化服务。9月8日,蚂蚁集团发布金融大模型,聚焦真实的金融场景需求,称在研判观点提取,金融意图理解,金融事件推理等领域达到行业专家水平。大模型在万亿量级Token的通用语料基础上注入千亿量级Token金融知识,并从300多个真实产业场景中提取高质量指令数据,形成金融专属任务性能优化的数据资产。据了解,蚂蚁金融大模型已经通过证券从业资格,保险从业资格,职业医师资格,职业药师资格等专业试题测试。Wall Street Journal报道,Meta正在开发新的AI系统,称其性能将是Lama2大模型的若干倍,公司预计明年初开始训练这个大语言模型。DeepMind研究者将AI大模型用作优化器,推出OPRO Optimization by Prompting的优化方式,不是通过数学定义或者编程求解来实现优化,而是用自然语言描述优化问题。而让大模型基于问题描述和历史方案重复生成新的方案,进而实现优化。通过OPRO优化大模型提示词,能够实现模型精准度最大化。斯坦福研究者使用GPT-4开发创意工具Spellburst,可以将艺术家的想法转化成代码,对作品的构思和修缮进行赋能。比如艺术家可以输入Prompt一束美丽明亮的玫瑰花图案的彩色玻璃,然后模型会生成代码进行概念渲染,同时生成一个动态控制板,用来进一步调整图像细节或者添加调整指令,比如让花朵变成暗红色。创作者还可以融合不同图像版本,比如结合第四版的花朵颜色以及第九版的花瓶形状。点击图像会显示代码,可以不用提示词而是通过编辑程序来进行微调。NextGPT是一个多模态大模型,可以处理文本、图像、音频、视频等任意组合的输入和输出任务。研究团队使用轻量型协调学习技术,利用编码端和解码端能够以最小的参数调整实现有效的语义协调。这里说一下协调所谓Alignment,是指通过使用一系列特定的技术来调整模型的参数,使得它在新任务上的表现可以更好。和Fine-tune相似,Alignment也是自然语言处理常用的技术NLP,但它通常只需要在一个很小的数据集上进行训练,而且Alignment不需要很多迭代。另外,团队还通过模态调换指令微调Reset,让大模型实现复杂的跨模态理解和推理能力,生成堪比人类水平的多模态内容。Rewindable AutoRegressive Inference,可倒回自回归推理技术,简称RAIN,能够让预训练大模型评估自己生成的文本内容,并使用该评估结果来指导反向调整和正向生成。通过让大模型评估增强自己的输出内容,RAIN不需要额外的数据或者耗时费力的Fine-tuning,就可以实现Model Alignment,模型调整。Refound这个工具,它采用自监督学习的方式开发,学习160万张视网膜图像,无需研究者逐一分析标注每张图片。Refound会像ChatGPT预测下一个单词、下一句话那样,预测图像应该是什么样的。视网膜可谓健康的窗口,因为这是人体表面唯一可以直接观察到毛细管网的地方。Capillary Network,如果一个人患有高血压,这样会影响全身血管的系统性心血管疾病,那么就可以从视网膜图像看出来。另外视网膜还是中枢神经系统的延伸,因此视网膜图像也可以用来评估神经组织的状况。回到这个Refound,它用160万张未标注的视网膜图像完成预训练之后,研究人员引入少量有标注的图像,比如100张帕金森患者的视网膜图像以及100张没有帕金森症的人的视网膜图像,来教这个模型学习特殊情况,将视网膜的特征与特定的疾病对应起来。目前该系统在检测眼部疾病方面表现良好。未来Refound或许还能应用在磁共振成像或者计算机断层扫描等三维甚至四维的图像领域。目前模型已经面向公众开放。Dialpad面向企业推出Dialpad GPT,利用实时生成式AI实现客服、销售、招聘等业务流程自动化,在防止数据泄漏、保护隐私的同时,能够通过实时的情感分析提供实时反馈。Dialpad GPT使用50亿分钟的真实商业对话进行训练,研发全程没有第三方参与,虽然更少但也更加专精、高效。巨深对话代理FirstChat基于大模型打造,用户通过与人形半身像的机器人对话,可以获取通用的以及专门场景的信息,比如介绍一个博物馆。在语音交互之外,FirstChat还可以生成面部表情。英国初创公司Wavy推出自动驾驶汽车系统Lingo One,能够用日常英语回答问题并解释为什么会做出特定的决定,比如解释为什么会在发现十字路口有行人的时候减速,为什么以特定的速度行驶等等。Lingo One通过人类驾驶的视频进行自主学习,同时利用大语言模型基于人类驾驶员的行为和驾驶数据输出文本答案。相较人类的答案,目前Lingo One的准确率在60%,还没有应用在自动驾驶汽车。9月6日,1801参数的Falcon开源大模型发布在Hugging Face Hub,使用4096个GPU对3.5万亿token的数据集进行训练,训练和优化使用了云机器学习平台Amazon SageMaker。而如果同ChatGPT比较,Falcon1801参数的大模型大概介于GPT3.5和GPT4之间。Last Mile AI完成1000万美元种子轮融资,谷歌的AI风险基金Gradient领头,平台旨在帮助软件工程师将生成式AI模型融合到自己的应用中,包括提供AI Workbooks,帮助用户以正式尝试不同的模型。AI Workflows可以将不同模型连接起来执行更加复杂的任务。AI Templates创建可重复使用的开发设置,进而与团队甚至Last Mile社区共享。开发和训练大语言模型需要强大的计算系统支撑,会消耗大量电力资源产生很多热量,于是数据中心需要用水来冷却设备。根据微软的环境报告,2022年全球用水量,微软的全球用水量近17亿加仑,相较2021年增加了34%。推测与公司的AI研究直接相关,17亿加仑水与64亿升水,也就是说如果一个人一天喝两升水,64亿升水可以喝877万年。而据了解,谷歌同期用水量也增加了20%。另外,加州大学研究团队估算,用户每问ChatGPT一系列问题,大概5到50个问题的话,就会消耗500毫升的水。这期节目就到这里,Thanks for listening!