大家好,这里是AI大模型周报2024年2月的第三季。OpenAI推出视频生成扩散模型SORA,取自日语单词空的发音,能够基于文本或图像生成60秒长度的不同清晰度的高质量视频。支持修改视频内容,比如让跑车在水下、丛林甚至太空的背景中行驶。也支持宽屏和竖屏,满足面向不同设备的内容创作等等。在世界模型方面,尽管SORA仍不能完美地模拟物理世界,但是也许一切只是时间问题。Google DeepMind等研究者对双机械手远程操作的低成本开源硬件系统ALOHA进行升级,推出ALOHA 2,具备四个摄像头视角,能够进行文具分类、倒可乐、开牛奶盒甚至变身爬手。Amazon AGI研究者面向文本到语音,也就是text-to-speech TTS领域推出BASE TTS。BASE的全称是Big Adaptive Streamable TTS with Emergent Abilities。模型参数10亿,基于10万个小时公共领域语音数据组成的数据集进行训练,是目前最大的TTS模型。语言专家对BASE TTS在数据集大小和模型参数的三种变体中的有限能力进行评估,发现语音自然度从BASE Small到BASE Medium有明显的改善。总的来说,BASE TTS生成的语音更加自然,与输入文本的错位更少,与参考说话人的语音更相似。Meta等研究者推出非自回归音频生成研码模型Magnet,可以在多个音频tokens流上直接运行。音频生成质量媲美领先的自回归极限模型,同时显著缩短了延迟。Magnet有望推进高质量音频实时生成的发展。AI Waves的研究者面向创意写作推出系列基础模型Weaver,旨在提升大语言模型的写作能力。经过微调,Weaver能够胜任创意写作和专业写作任务,对其职业写作者的偏好习惯,执行更加多元的指令。Weaver包括参数规模不同的四个模型,其中341参数的Weaver Ultra在多个写作场景中表现优于GPT-4。卡耐基梅隆大学和苹果的研究者面向大模型训练数据的质量问题推出WAP,全称是Web Rephrase Augmented Pretraining,使用现有的指令微调模型对网上的文件进行改述,比如转成类似Wikipedia的风格或者转成问答格式。使用WAP基于真实文本与合成文本的预训练能够有效缩短训练时间,以相同的预训练算力预算提升零样本问答准确度。南加州大学的研究者面向虚假信息问题推出FactGPT,使用合成数据集训练模仿人类判断,高效识别社交媒体内容的虚假信息,展示了大语言模型支持事实核查的潜力。浙江大学等研究者面向6到12岁的儿童推出自动化视觉编程学习AI系统ChatScratch,利用互动的故事本、数字绘图和图像生成技术提升创造力,同时利用专门的Scratch大模型进行专业的编程指导,有助于为儿童创建高质量个性化的Scratch项目。清华大学的研究者推出多语种监督微调数据集UltraLink,包括5种语言的近100万个样本,并且可以简单扩展到其他语言。UltraLink不止简单地翻译英文指令,而且考虑大模型的泛语言能力,基于该数据集训练的语言模型在多项任务中表现不俗。复旦大学的研究者推出开放环境的自组织代理S-Agents,参考人类组织行为以沙漏型的代理架构来平衡信息优先级,以非阻碍型协作的方式让Agents实现异步任务执行,从而自动协调一组代理在没有人为干涉的情况下高效处理开放动态环境的挑战。实验发现S-Agents可以在Minecraft环境中高效执行协作性的收集和建造任务。在现代科学和工程中,片微分方程有助于对涉及多种变化率的复杂物理系统进行建模,比如模拟经过飞机记忆的空气流动,还有模拟空气中的污染物的扩散以及模拟恒星坍塌成黑洞等等。数据驱动的代理模型Surrogate Models虽然也能解决这类方程,但是训练成本高昂。为此,佐治亚理工学院等研究者推出物理增强的深度代理方法PEDS,全称是Physics Enhanced Deep Surrogate,旨在面向复杂的物理系统开发高效的代理模型。PEDS使用物理模拟器帮助训练神经网络以匹配高精度数值系统的输出,目的是借助某个领域的专家知识,比如这里是物理学,来生成准确的结果,而不是仅仅在这些问题上投入大量计算资源用蛮力来找到解决方案。研究发现这些新模型处理片微分方程时的准确度是其他神经网络的三倍,并且只需要大约1000个训练点,将所需的训练数据减少了至少100倍。Ohio State University的研究者面向化学领域推出高质量指令微调数据集Small Instruct,包括14项化学任务和300多万高质量样本,支持训练和评估化学大模型。另外,团队基于Small Instruct微调了4个开源大模型,分别是Galactica、Lama2、CodeLama和Mistral,创建名为Lusmo的大模型系列。在与化学相关的任务中表现优于GPT-4等现有大模型。MIT的研究者推出基于大模型的蛋白质设计平台ProAgents,支持多个能力不同的AI代理在动态环境中灵活自主地解决复杂的任务,包括多个领域的知识检索、蛋白质结构分析、物理模拟、结果分析等任务。Illuminate是一个利用提示子工程发现抑郁症患者并给出分析和治疗建议的方案,对GPT-4、Lama2Chat和Gemini三款人机大模型进行微调,通过分析医疗对话和线上论坛的文本数据,以有效地诊断、解释和辅助治疗抑郁症。Zara AI等研究者推出Legal Lens,旨在利用大语言模型识别非结构化数据中违反法律法规的内容,并将这些违反内容与受到影响相关人物联系起来。研究者基于历史集体诉讼案和法律新闻利用大模型生成了两个专门数据集,并对多个语言模型在法律NLP领域的应用进行评估。本期节目就到这里,前面提到的论文链接请参考视频下方的简介部分。Thanks for listening!