大家好,这里是AI大模型周报2024年9月的第四期。University of Notre Dame的研究者面向食品计算Food Computing推出多模态基础模型Chef Fusion,能够完成各类与食品计算相关的任务,包括食品理解与识别,菜谱生成,食物图像生成等等。南加州大学等研究者面向风味科学Flavor Science,推出Fit Puzzle基准,包含978种食物和1766个风味分子画像,并融合上下文学习和检索增强技术,采用Sangin Ziffick Agent的方法开发大模型智能体作为风味科学家,生成有依据的假设,赋能风味开发。University of Illinois等研究者面向跨学科研究构思Research Ideation推出Persona Flow系统,利用人物角色模拟Persona Simulation来支持跨学科的科研构思。研究发现,在构思阶段使用多个模拟的专家人物角色,能够在不增加认知负荷的情况下显著增强输出质量,比如批评意见的相关性,研究问题的创造性等等。用户还可以编辑Persona的特征,提高对研究构思的掌控度。香港中文大学深圳等研究者面向多模态大模型的长文本能力,推出Long LAVA模型,Long Context Large Language and Vision Assistant,采用混合了Mamba与Transformer的架构,对于视频理解,高清图像理解,多模态智能体等任务,能够更好地平衡效率和有效性,就是Efficiency and Effectiveness,而不仅在多个基准的表现良好,而且保持高吞吐量和低内存消耗。阿里巴巴研究者以动作类角色扮演游戏黑神话悟空为平台,探索视觉语言模型基于纯视觉输入,Visual Only Input,来实现复杂动作输出,Action Output的能力边界,提出VARP智能体框架,就是Vision Action Role Playing,由一个动作规划系统和一个视觉轨迹系统组成。研究者指定了12个游戏任务,其中75%聚焦战斗,而这个框架能够以90%的成功率完成初级和中级的战斗场景。2024云期待会,阿里云发布通义千问新一代开源模型Quinn 2.5,全系列涵盖多个尺寸的大语言模型、多模态模型、数学模型和代码模型,总计上架100多个模型。其中旗舰模型Quinn 2.5 72B,它的性能超越了Lama 405B,在登全球开源大模型王座。而数学模型Quinn 2.5 Max,支持使用四维链和工具集成推理,来更好地解决中英数学题。代码模型Quinn 2.5 Coder,在显著提升代码生成推理修复等任务能力的同时,保持数学通用能力等方面的优势。GitHub开放O1 Preview和O1 Mini的早期访问权,用户可以在VS Code的Copilot Chat选择使用O1模型代替当前默认的GPT-4O,应对复杂的编程挑战,也可以在GitHub Models测试O1模型,进而融合到自己的应用中。字节跳动发布音乐大模型Z Music,能够生成富有表现力的多语言人生音乐,包括歌曲续写和风格转换,也可以生成无人声的伴奏音乐。这是从歌词到功能谱到歌曲的生成,这是对音乐音频进行精确的音符级调整,Note Level Editing。用户也可以提供10秒钟唱歌或者讲话的音频,用自己的声音生成歌曲演绎,比如Happy Birthday to you,Happy Birthday to you,这Spring in the Home,The Limistening in the Rain。哈维在2024年全年接大会期间发布Ken 8.0以及OpenMind应用室能套件,并宣布未来三年每年将投入10亿元来发展昆鹏双腾的原生生态与人才,赋能百万原生人才,孵化千个原生项目。硅谷科技评论SVTR AI创投库推出全球AI黄埔军校Top 10,按照创始人工作经历排名,谷歌一季决成,按照创始人教育背景排名的榜单中,斯坦福位居第一,清华大学位居第五。这期节目就到这里,前面提到的论文链接请参考视频下方的简介部分。Thanks for listening!