大家好,这里是AI大模型周报2023年12月的第四期。阿里巴巴研究者推出可控视频生成框架Dream Moving,针对以人为中心的内容生成,根据人物的身份和动作序列,也就是Target Identity和Posture Sequences,来生成高质量的人类跳舞的视频。模型使用Video Control Net来控制动作,使用Content Guider来保持人物身份,也就是人脸还有衣着的一致。这是仅根据文本生成视频,这是输入文本加图像,这是指定五官和衣着,这是根据风格化的图像生成特定人物动作的视频。苹果等研究者推出神经渲染架构HUX,全称Human Gaussian Splats,这里说一下Gaussian Splatting,高斯建硕,是指可以根据多个角度的图像进行实时的3D重建和渲染。HUX利用3D Gaussian Splatting来对50到100帧的视频进行训练,即可在30分钟内创建一个包括背景的可以自由活动的3D Avatar。HUX还支持多人的新场景渲染,就可以不止是一个人,它可以实现60fps,也就是60帧每秒的高质量渲染,训练速度提升100倍。牛津堡科技大学和苹果的研究者利用基础模型赋能虚拟助手服务,旨在让用户与智能手机、智能手表、智能音箱等设备更加自然的交互。研究者提出一种多模态模型,只需要较少的训练数据就能从背景语音里面有效地区分出来用户对设备说的话,从而免去使用触发词的必要。触发词就是trigger phrase,比如Hey Siri。瑞士洛桑联邦理工学院和苹果的研究者推出4M多模态训练框架。4M代表Massively Multimodal Masked Modeling,大规模多模态掩码建模。这里补充一下掩码建模Masked Modeling,是指对文本或图像输入进行部分掩盖,然后训练模型根据没有掩盖的部分背景来预测被掩盖的部分是什么。4M方案将文本图像几何语义等模态的representation space整合起来,对应各自的令牌tokens,然后对令牌的任意子集进行多模态掩码建模。使用4M框架训练的模型能够执行多样的视觉任务,包括生成generation、编辑edit还有推理inference等等。微软的AI聊天机器人Copilot新增Suno插件,支持定制AI歌曲。驻地剑桥的AI音乐初创公司Suno在Discord提供AI作曲作词服务。现在Copilot用户只需登录账号授权Suno插件,输入一到两句提示词,描述想要创作的歌曲,比如创作一首关于阿拉斯加夏天的民谣歌曲,或者按照周杰伦的风格写一首关于猫咪的歌曲,就能获得一首一到两分钟时长配有歌词的原创歌曲。Suno保留作品的所有权。Google DeepMind推出FineSearch,代表Searching in the Function Space,来旨在寻找数学和计算机科学领域的新的解决方案。团队结合预训练大模型Cody,就是谷歌POM2大模型针对计算机代码微调的版本。团队会结合Cody来负责以计算机代码的形式提供有创意的解决方案,同时利用自动化的评估器,An Evaluator,来负责防止AI幻觉问题。FineSearch通过来回迭代演化形成新的知识。它已经发现了CAPSAT Problem上线级问题的新的解决方案。这是第一次利用大模型实现复杂纯数学问题的新发现。在实际应用方面,FineSearch也用来发现Bin Packing Problem装箱问题的更有效的算法。它的成果可以应用在非常广泛的领域,比如提高数据中心的效率。Google DeepMind推出文声图技术Imogen 2,通过增加图像说明优化训练数据集,Imogen 2能够更好的理解图像和文字之间微妙的关系,按照提示词生成极具真实感的高质量内容。比如理解美国诗人Phyllis Whitley的赞美诗,Soft Pearl the Streams, the Birds Renew Their Notes, and through the air, their mingled music floats。西水鼓鼓,鸟儿周周,空气中弦律交织舞动。这样微妙的关系来形成这样的画作,生成这样的画作。开发者可以通过Google的Vertex AI的Imogen API来使用Imogen 2。Google的研究者推出能够自我完善进行多步骤推理的大模型代理LLM Agent,采用React方法进行训练。React就是Reason Plus Act,是Princeton University和Google研究员推出的一种能够在语言模型中协同Reasoning推理与Acting行动的方法。据称相较模仿学习和增强学习的方式,React的绝对胜率分别在34%和10%。此次推出的React大模型代理使用REST算法进行优化。REST全称是Reinforced Self Training,增强自训练,也就是基于先前的轨迹反复训练,利用高质量的合成数据来持续进行自我完善和自我蒸馏,应对复杂冗长的自然语言问题。结合REST和React微调的小模型在性能不减的前提下,参数量可以减少1到2个数量级。新加坡南洋理工大学的研究者面向视频生成所存在的时序不一致画面不自然的问题,推出FreeNet抽样策略,通过反复优化初始噪声的低频部分,FreeNet无需额外的训练或微调,就能轻松融合到文本生成视频的扩散模型中,稳定地提高生成视频的推理质量。比如右下角用VideoCrafter生成的小猫喝啤酒的视频,融合FreeNet的视频更符合文本的语境。南洋理工大学和上海人工智能实验室的研究者推出H-SAM。SAM代表Segment Anything Model,这是Meta在2023年4月发布的一个视觉分割基础模型,能够将任何图像的任何物体一键分割出来。H-SAM是SAM的一个变体,面向边缘端设备,基于SAM打造一个轻量型的基于CNN,也就是卷积神经网络的架构,采用Prompt in the Loop的知识蒸馏或者说知识提取的方式,能够在保证准确度的同时高效地执行任务,也就是保证Efficiency and Accuracy。H-SAM的速度是SAM的40倍,也是第一个能够在iPhone 14上以超过每秒30帧的速度运行的SAM变体。Salesforce AI等的研究者推出生成式基础模型Unicontroll,能够在一个框架内处理多种条件生成图像的任务。条件生成图像就是Conditioned Image,C2I,集中解决空间、结构及和控制等内容生成难题,支持像素级精确的图像生成。由语言提示词引导图像的风格和背景,同时考虑各种视觉条件,Visual Conditions,来生成合理的结构。根据提示词的背景和前景条件生成图像之外,Unicontroll能够灵样本适应新任务,包括图像去模糊、De-blurring、图像上色、Colorization和图像修复、Inpainting。同时推出高性能应用服务HAI,也就是Hyper Application Inventor,称10分钟可以帮助用户开发自己的专属AI应用。HAI支持自动配置性价比更高的GPU算力,一键部署依赖环境,可以通过选择模型定义算力类型硬盘大小来完成。此外,HAI预装有Stable Diffusion,ChatGLM等热门模型。百度智能云表示自8月底文心大模型全面开放以来,千帆大模型平台上大模型API日调用量增加10倍。目前千帆平台已经累计服务4万多家企业用户,累计帮助企业用户精调近1万个大模型。相较自建系统训练大模型,使用千帆平台训练的成本最多可以降低90%。字节跳动智能创作语音团队SAMI代表Speech Audio and Music Intelligence,这个团队推出端到端音乐生成模型Stamp Jam,能够听取音乐背景,生成高质量的符合背景的内容。华中科技大学字节跳动等的研究者推出基础模型Glee,聚焦定位、识别图像和视频中的目标对象。模型使用图像编码器、文本编码器以及视觉提示器,Imaging Encoder, Text Encoder and Visual Prompter,来处理多模态输入,能够即时解决各种以目标对象为中心的下游任务,包括物体检测、实例分割、物体追踪等等。税务服务机构H&R Block发布生成式AI报税助手AItax Assist,回答用户关于税务的问题,包括减税、抵税、税收法规等等,并且支持连线人工服务。值得一提的是,今年9月商业软件公司Intuit也推出生成式AI工具Intuit Assist,可以帮助小型企业了解税务信息,将在2024年1月全面开放。密歇根大学等的研究者推出Perseus,因先作优化架构,通过规划正向计算