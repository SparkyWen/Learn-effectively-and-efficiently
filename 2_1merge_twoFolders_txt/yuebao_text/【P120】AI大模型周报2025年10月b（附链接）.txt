大家好,这里是AI大模型周报2025年10月的第二期。Figure AI推出第三代人型机器人Figure03,重新设计传感装置和手部系统,专门适配公司自研的VR类大模型Helix,适用于家庭场景,支持长程打扫卫生,清洗餐具并收纳,洗衣服,叠衣服等,也可用于前台接待,包裹检测,快递送货等场景。公司已新建供应链面向家庭以及商业场景,以较低成本大批量制造Figure03。特斯拉时隔近一年发布重大更新FSD,就是Full Self Driving V14,可以在驾驶者的监督下自主行驶,包括启动,变道,绕行,停车等等。有用户惊叹14.1版的自滑体验,认为这本FSD已经可以胜任100%的驾驶行为。Elon Musk表示,14.3版会让人值得出由自己的意识。Google DeepMind推出Gemini 2.5 Computer Use模型,基于Gemini 2.5 Pro的视觉理解和推理能力,实现智能体与用户界面的交互。模型在多个网页和移动端控制基准的表现领先,且延迟更低。我们在8月的第一期周报中介绍过Google Labs推出的Opal,它现在宣布这个零代码应用创建服务在美国之外又覆盖15个国家,同时新增工作流故障排除,也就是Advanced Debugging for Workflows等功能,让创建AI迷你应用更快更简单。OpenAI推出Apps in ChatGPT功能,用户可在ChatGPT聊天界面直接与第三方应用交互。首批支持的应用包括Booking.com,Canva,Coursera,Figma,Spedia,Spotify和Zillow,今年还将上线11款应用,同时推出基于MCP的Apps SDK预览版,帮助开发者更好地设计应用逻辑与界面。OpenAI启动AgentKit工具集,帮助开发者高效创建,部署和优化智能体。新增工具包括多智能体工作流画布AgentBuilder,数据和工具管理连接器ConnectorRegistry,以及将个性化的智能体经验嵌入产品的ChatKit,同时扩展提示词自动优化等新功能,衡量和提升智能体的性能。谷歌为Gemini CLI发布官方增强插件Genkit Extension,可让Gemini CLI深度理解Genkit的架构,模式,并融合Genkit开发工具,让开发者可以直接在终端创建,调试和优化AI应用。OpenAI宣布Codex全面开放并推出Slack融合Codex SDK核心的管理工具等功能。剧中Codex的日使用量自8月初已增长超过10倍,用户覆盖从多灵国等初创公司到思科,Lockton等大型企业,增长最快的模型之一GPT-5 Codex发布前三周已处理超过40万亿tokens。Cursort推出Plan Mode,可以在开始复杂的编程任务之前基于用户自己的代码库查找相关文件等,撰写详细的计划,计划可编辑,可存储,能够显著提升生成代码的质量。Anthropic公开测试CloudCode plugins,支持将Slash commands,子智能体,MCP服务机,还有hooks等多种扩展组件打包成一个可共享的模块,实现CloudCode定制化体验。蚂蚁集团前沿AI研究团队Inclusion AI发布稀疏混合专家通用语言模型Lin ET,参数1万亿,每Token活跃参数500亿,在多个复杂基准的表现领先,尤其擅长代码生成,软件开发,专业数学,逻辑推理等,兼具准确和效率。11 Labs推出对话流编辑器Agent Workflows,无需将所有商业逻辑整合到单一智能体,支持解构复杂场景,根据需求对接到专门的子智能体,sub-agents,或者人类操作者,并且每个步骤可以根据任务类型选择合适的大模型。MIT Media Lab发现按照指示提供信息的AI工具可能让用户过度依赖,甚至导致长期认知能力衰退。对此,研究者推出NeuroChat神经自适应聊天机器人,可以根据用户大脑活动实时调整交互方式。NeuroChat利用脑电图实时读取大脑信号,从而根据用户的专注程度调整输出方式,比如简化复杂内容或者引导深入思考,实现个性化互动式的学习体验。xAI正在进行一轮200亿美元的大规模融资,其中包括来自NVIDIA的股权融资。本轮融资将分为75亿美元的股权融资和125亿美元的债务融资,并将通过特殊目的实体-SPV购买英伟达处理器。AMD和OpenAI达成战略合作,后者将在未来几年部署6GW的AMD GPU,预计2026下半年开始部署第一个GW的AMD Instinct MI450 GPU。作为协议的一部分,AMD向OpenAI发行最多1.6亿股AMD普通股的认股权证,相当于AMD约10%的股权。彭博社报道,OpenAI与英伟达等通过循环交易网络Web of Circular Deals助推万亿美元AI市场,担忧这场万亿规模的AI热潮是由相互勾连的商业交易所人为维系的。此次节目就到这里,前面提到的论文以及项目链接请参考视频下方的简介部分。Thanks for listening!