大家好,这里是AI大模型周报2024年6月的第四季,Runway推出视频生成模型Gen 3 Alpha在Gen 2的基础上大幅提升保真度和一致性,更加流畅自然,向构建通用世界模型General World Models更进一步。Gen 3 Alpha基于视频和图像训练,将负能Runway的文生图、文生视频以及图生视频工具提供更多支持细力度控制的功能。Google DeepMind推出视频生成音频技术V2A Video to Audio,将视频画面与自然语言文本提示结合起来,能够生成与视频内容同步的声音效果,包括音乐、音效、人声,比如这个。在视频音频之外,V2A的训练还用到AI生成的注释,包括生成音效描述和对话脚本,将特定的音频事件Audio Events与视觉场景Visual Scenes联系起来。四节跳动Seed Team推出文本生成语音系列模型Seed TTS,能够生成与真实人声并无二致的语音,支持控制各种声音特征,比如声音的感情色彩,包括愤怒、开心、悲伤、疑惑,也可以根据音色提示Timbre Prompt来将原音频的内容转换成声线语气一致的音频,比如这个。今天为大家带来一部高分经典悬疑电影。我给大家深度解说《禁闭岛》。这是原音频,那参考的音色是这样的。皇上请三思,皇后娘娘都是为了万岁爷着想。给就是荣某某的声音,那用荣某某的声音来读这段原音频的话就是。今天为大家带来一部高分经典悬疑电影。那如果参考的音频音色是这样的。进来又能怎么样,他会有多么的伤心呢。读出来的效果就是。今天为大家带来一部高分经典悬疑电影。Seed TTS还支持修改音频的内容,调整语速,支持生成包含多角色对话的有声书,支持多语种转换,包括生成口型一致的另一种语言的视频,比如这个原视频是英语。把它转换成西语,口型也是一致的。现在年轻的专业人士在周末工作。这个趋势是由TikToker Marisa Mays发起的。因为它发布NemoTron 4模型家族参数3400亿,是用来自高质量数据集的9万亿tokens进行训练,包括NemoTron 4 Base, Instruct和Reward,可以负能各类研究任务和商业用途,尤其用于生成合成数据,来训练较小的语言模型。Train Smaller Language Models。另外,因为它股价再创新高,市值达到3.34万亿美元,超越微软成为世界第一。潘斯贝尼亚州立大学研究者面向大模型协作创作,也就是由多个大模型共同创作故事,推出数据集Collab Story,使用开源的指令微调大模型生成了超过32000个最多由5个大模型共同创作的故事。论文指出Collab Story有助于理解和辨别多模型协作,也就是LLM to LLM Collaboration,而这关乎抄袭检测,维护学术诚信,应对版权侵权等问题。新加坡国立大学研究者面向大模型代理在真实世界场景中的规划能力推出Proactive Agent Planning任务,让代理基于用户对话和环境互动来处理不清晰的用户指令,并借助外部工具收集有效信息生成符合需求的计划。多代理框架CEP,就是Clarification Execution Planning,由三个代理组成,分别负责澄清需求,执行和规划。评估证实了CEP在需求澄清,工具学习和规划方面的有效性。J.P. Morgan AI Research研究者面向旅行规划推出混合方法TripPal,将大语言模型和自动规划器,也就是Automated Planners结合起来,由大模型获取旅游信息和用户信息,翻译成能够喂给规划器的数据结构,然后由自动规划器生成满足需求的高质量旅行规划。实验显示相较大语言模型TripPal能够为各类旅游场景生成更好的旅行规划。那这个图的对角线以下表示TripPal生成的计划质量更高。南洋理工大学深圳哈尔滨工业大学和阿里巴巴大魔院的研究者面向城市规划和管理推出微调大模型Urban LLM,旨在处理城市场景中的各类问题,能够将相关问询解构成比较容易处理的子任务,并为每个子任务找到适合的AI模型生成全面的问询回复。实验发现在城市活动规划管理方面,Urban LLM处理相关问题的表现明显超过LAMA和GPT系列等模型。韩国科学技术院的研究者面向大模型决策推出检索增强生成方法PlanRAG,迭代的计划检索增强生成。第一步是Planning,基于PlanRAG的语言模型会分析数据模式和问题来制定一个初步计划,指导后续的数据检索和分析步骤。然后是Retrieving,检索,通过生成数据查询检索散布的数据,支持决策。接下来是Replanning,再规划,它会根据检索结果评估是否需要重新制定计划来进行更加深入的分析或者纠正之前的方向。如果需要的话,PlanRAG就会重复前面的规划和检索步骤,直到最后完成决策Answering。实验表明PlanRAG能够有效处理决策问答任务。韩国科学技术院开AI和现在技术公司围绕逆向学习提出Snap框架,旨在让大模型有选择地遗忘信息。Snap的特点包括一、用负向指令训练大模型,用GPT-4和GPT-3.5建立遗忘集Forgetting Set,让大模型在被问及特定信息的时候输出无法提供答案的回复。二是硬保留数据增强Heart Retaining Data Augmentation,用GPT生成相关指令和对应的正常回复创建保留集Retaining Set。三是通过Vassstein正则化,确保在指令调整过程中模型的一般能力不会受到负面影响。评估发现Snap能够在保留大模型原本能力的同时成功遗忘特定的信息。大语言模型可以记忆训练数据并进行重复,导致隐私和版权风险。为了弱化这种记忆现象,马里兰大学的研究者推出名为Goldfish Loss金鱼损失的修改方法,在训练过程中随机选择一小部分tokens不参与损失计算,于是这些tokens不会被模型记忆,从而防止模型完整复现一连串tokens。实验显示Goldfish Loss可以在几乎不影响下游基准测试性能的情况下显著减少可提取的记忆,有望帮助数据所有者与模型训练者和谐共存。南加州大学研究者对大模型的社交智能Social Intelligence进行研究,开发Inner Intent框架,将大模型置于交互式游戏环境中,通过它们理解和管理意图的能力来衡量它们的社交智能。研究聚焦社交智能的四个维度,包括情境感知、自我调节、自我感知、心智理论。这些维度分别对应意图选择、意图遵循、意图总结和意图猜测。研究发现大模型正确选择意图的准确率高达88%,但是猜测他人意图的能力明显更弱,比人类的表现落后20%。斯坦福大学研究者面向人形机器人模仿学习推出全战系统Human Plus,可以基于人类数据学习复杂的自主技能。研究使用40小时的人体运动数据集在模拟环境中训练Humanoid Shadowing Transformer策略,配合RGB相机以及模仿学习算法,实现从模拟到现实的迁移,机器人直接在真实世界中学习穿鞋、站立、行走等全身控制和运动技能。复旦大学研究者面向具备自主演化能力的通用型智能体推出Agent Gene框架,包括一个集成多种智能体环境和任务类型的交互平台,一个基准测试工具集Agent Vow,以及高质量轨迹数据集Agent Trash和Agent Trash L。同时推出新算法Agent Evo,探索大模型通用智能体的演化能力。实验发现演化智能体的表现与领先模型的结果相当。由前谷歌研究员创建的初创公司Sakana AI正在推进1.25亿美元新一轮融资,估值将达到10亿美元。公司成立于2023年7月,致力于打造更小更灵活的AI模型。大模型赋能的搜索引擎开发者James Bark完成6000万美元融资,估值2.6亿美元。搜索引擎James Bark内置聊天机器人辅助用户搜索理解特定的主题和内容,旨在提供全面可信的搜索服务。企业级AI应用评估和可观测平台Maxim AI完成300万美元融资,公司在2023年成立,致力于打造标准化可扩展覆盖AI应用开发全生命周期的评估平台。智源研究院FlagVal更新大语言模型测评能力榜单