大家好,这里是AI大模型周报2024年5月的第二季。5月13日,OpenAI推出新一代生成模型GPT-4O,O4Omni,全能,在文本、推理、代码智能等方面的性能达到GPT-4 Turbo的水平,在多语种、音频、视频能力方面则更胜一筹,支持文本、语音、图像多模态的任意组合作为输入和输出,反应极快,比如对语音输入的反应速度接近人类,能够理解人类情感,向更加自然的人机交互更进一步。5月14日,谷歌在Google I.O.大会宣布Gemini 1.5 Pro上下文长度扩展到200万tokens,推出更新更快保留多模态推理和长文本能力的Gemini 1.5 Flash,推出新一代开源模型Gemma 2,参数270亿,表现与700亿参数的Lama 3相当,将在今年6月启动。推出通用型AI助理Project Astro和视频生成模型Vio,前者能够理解复杂的动态环境并做出即时回应,后者能够根据文本、图像和视频提示生成1080p高质量视频,直接对标OpenAI的GPT-4O和Sora。腾讯推出文生图大模型会员GIT,基于Diffusion Transformer架构,支持中英双语细腻度理解,能够与用户进行多轮对话,分析理解长篇文本中的信息,生成并完善图像,支持生成不同清晰度、不同尺寸的图像。相较同类模型,会员GIT表现较好,比如这里会员GIT生成的妆容似乎更加精致,这里只有会员GIT和DALL·E 3生成的是包子,而会员GIT的则更符合狗不理包子以及特写镜头的条件。上海AI实验室和香港中文大学的研究者推出Illumina T2X系列模型,可以根据文本指令Text Instructions将噪声转化成图像、视频、音频以及多视角3D物体,支持在一个框架内进行不同模态的训练,灵活生成多模态数据。比如文生图模型Illumina T2I,也就是Text to Image,能够以任意分辨率和长宽比生成高质量图像,支持复杂的指令,支持指定风格,也支持修改风格和内容。而它的训练算力成本只有PixArt Alpha的35%。人生合成平台11 Labs推出AI音乐生成器。尽管目前还未开放,但是生成的多类音乐的样本质量似乎已经超过Udio。样本歌曲时长至少两分钟,超过Udio的30秒和Suno的一分钟。华盛顿大学和Adobe Research研究者面向增强现实AR推出Sonify AR,为增强现实体验生成背景内容相匹配的声音。这个基于大模型的AR音效生成系统会识别可能发出声音的事件,以文本的形式收集背景信息,结合真实世界的环境信息,实现AR体验可听化,就是Sonification。语术科技推出人形机器人UHG-E,起步价9.9万元人民币,而9个月前的UHG-H-E它的售价是9万美元。相较H-E以及Optimist,Figure 01等机器人,UHG-E它的体型更小,体重仅70斤,支持折叠存放,主要面向科研教育场景。它有23到43个关节电机,足以实现精细的运动控制,可以每秒2米的速度运行,接近人类慢跑速度。在外力冲击下保持平衡的能力也很优秀,并且和H-E一样配备3D LiDAR传感器和深度摄像头,支持360度全景深度感知。南洋理工大学的研究者推出四维时空全景图像系统PSG4D,全称是4D Panoptic Scene Graph,能够捕捉理解三维空间的稀里度语意以及时间维度对应的信息。通过融合大语言模型与PSG4D,能够理解动态场景,支持任务执行。天津大学和华为诺亚方舟实验室的研究者推出LFED文学小说评估数据集,旨在评估大模型对长篇小说的理解和推理能力。团队收集了95部中文或者译成中文的小说,覆盖广泛的主题,跨越几个世纪,对小说类型、人物数量、出版年份等特征对大模型评估结果的影响进行了分析。实验发现目前主流大模型还不能完美地处理长篇小说的相关问题,比如ChatGPT在零样本设置下仅能有效处理57.08%的问题。深圳市大数据研究院的研究者推出SMURFS多代理框架,旨在变革大语言模型的应用,通过创新的提示策略在模型中分配不同的角色,从而将传统的大模型转化成多代理协同的综合体,无需额外训练也能增强任务结构和执行能力。接触外部工具高效地完成复杂的任务,评估发现SMURFS的效果明显。中国科学院香港创新研究院的研究者面向外科手术推出VS Assistant,全称Versatile Surgery Assistant,多功能手术助手,利用多模态大模型旨在理解外科医生的意图并完成一系列理解任务,比如手术场景分析、手术工具检测等,辅助手术流程。基于神经外科数据的大量实验证明,相较现有大模型,VS Assistant能够更加准确地理解人类医生的意图。多伦多大学英伟达等研究者推出手术机器人模拟框架Orbit Surgical,基于物理现实使用NVIDIA Omniverse渲染模拟手术环境,通过并行GPU进行增强学习和模仿学习算法的训练。Orbit Surgical能够让机器人实时捕捉来自人类专家的输入,利用真实世界的演示在虚拟环境中学习策略,并反过来赋能人类医生的手术技能,就是Sim2Real。George Mason大学的研究者推出IntelliExplain,帮助非专业程序员通过自然语言编写代码。用户用自然语言提出一个问题并提供任务相关背景,由IntelliExplain生成原代码并且用自然语言解释,和用户确认自己对这个问题的理解。如果理解不对,用户可以再用自然语言反馈让系统更正错误。和Vanilla GPT-3.5的比较发现,IntelliExplain对非专业程序员更加友好。清华大学的研究者面向大模型水印推出开源工具包Mark LLM。为实现大模型水印算法提供一个统一的、可扩展的、可以轻松使用的框架。另外,Mark LLM支持让水印算法的底层机制自动可视化,并且提供全套12个评估工具帮助削弱大模型滥用的潜在风险。明依万物开源大模型1.5,包括一系列预训练和微调模型,进一步提升了编码、数学、推理和指令遵循能力。多个基准测试发现,341参数的1.5指标与700亿参数的Lama3相当。Hugging Face推出Zero GPU项目,宣布提供价值1000万美元的免费共享GPU,旨在帮助小型开发者、学者、初创公司等减轻GPU成本负担,对抗AI进步中心化的趋势。To counter the centralization of AI advancements.字节跳动自研大模型豆包在火山引擎对外开放了服务,推理输入价格相较行业价格低99.3%。过去一年,豆包大模型从1.0进化到3.0,在公司内部拥有50多个应用场景,日调用量达到1200亿tokens。目前由豆包大模型支持的AI应用助手豆包APP累计下载量超过1亿,桌面家应用端月活用户2600万,支持创建的智能体总量超过800万。韩国AI芯片初创公司DeepX完成8000万美元C轮融资,估值5.29亿美元。公司在2018年由前苹果和思科工程师创建,生产的芯片主要面向消费者电子产品、AI服务器等。下一步计划推出新一代大模型设备端解决方案。英国爱丁堡AI初创公司Moted AI完成600万英镑总资轮融资,公司成立于2023年,专注于中流AI模型。帮助小型企业以较少的成本创建定制化AI模型,用小语言模型,也就是Small Language Models,解决专门领域的问题。这期节目就到这里,前面提到的产品以及论文链接请参考视频下方的直接部分。Thanks for listening!