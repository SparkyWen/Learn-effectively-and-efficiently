大家好,这里是AI大模型周报2024年7月的第四期Mistral AI面向数学推理和科学发现推出71参数大模型Mathsroll,上下文窗口32K,基于71参数的Mistral构建,在各行业标准基准的推理能力领先,尤其在MATH和MMLU基准的通过率分别为56.6%和63.4%,这是不同学科的MMLU的表现。另外,Mistral面向代码生成推出CodeStroll Mamba,使用Mamba2架构,不同于Transformer模型,Mamba具有线性时间推理优势,理论上支持无限长的输入和快速回复,而这尤其适合代码生成的场景.CodeStroll Mamba和领先的Transformer模型表现相当。香港中文大学的研究者面向大模型下视觉变形下的数学解题能力推出Mavis数学视觉指令微调分式,旨在完善三个关键领域,分别是数学图形的视觉编码、图形语言对齐以及数学推理技巧。研究者首先创建Mavis Caption数据集,包含55.8万个图形注释对,也就是Diagram Caption Pairs,通过对比学习来微调视觉编码器Clip Mass,然后让Clip Mass与大语言模型对齐,最后使用包含90万个精选的视觉数学问题的Mavis Instruct来微调,让多模态大模型具备优秀的数学推理能力。71参数的Mavis表现在开源的多模态大模型中明显领先。MIT的研究者面向核心设计推出具有物理感知能力的生成式AI平台Atom Agents,利用多个具备不同能力的AI智能体,包括知识检索、多模态数据融合、物理模拟等智能体。他们通过在动态的环境中自主协作解决复杂的材料设计问题。Atom Agents能够准确预测各类核心的关键属性,提高多目标设计任务的效率,也望赋能生物医药材料工程,可再生能源,环境可持续等领域。非盈利AI for Science研究实验室Future Health的研究者推出语言代理生物学基准LabBench,全称是Language Agent Biology Benchmark。数据集汇集超过2400个多选题,旨在评估AI系统的生物学研究能力,包括文献检索和推理能力,数据解读能力,接入和导航数据库的能力,理解控制DNA以及蛋白质序列的能力等等。研究者对若干前沿语言模型的科学任务能力进行评估,并将结果与人类生物专家进行比较,认为能够在LabBench任务中稳定获得高分的AI系统更能成为合格的研究助手。卡奈基梅隆大学的研究者推出物联网多传感大语言模型IOT-LM,多传感Multi-Sensory覆盖动作、温度、定位、图像、深度、声音、传感器等模态。IOT-LM得益于两大技术贡献,一是专为多传感预训练和指令微调打造的物联网数据集Multi-IOT,包含12种模态8项任务的115万多个样本。二是新的多传感多任务适配层,实现不同模态和任务之间的信息共享。IOT-LM展现出优秀的互动问答、推理和对话能力。加州大学的研究者面向计算机科学教学设计了基于大模型的辅导系统Course Assist,利用检索增强生成,也就是RAG以及用户意图分类和后处理,保证生成的内容符合特定的课程学习目标。使用一门编程语言课的问答对数据集进行评估,发现Course Assist表现明显超过基线水平。纽约大学尖端分校的研究者推出自动游戏生成系统Gavel,将Ludi用作基础数据集。这个通用的游戏系统主要用于测试、分析和设计各类棋盘游戏。研究者基于大模型和引化计算的最新进展,训练了一个能够改变融合游戏和游戏机制代码的模型,使用Mapping Leads算法引化式地优化游戏质量和多样性。佩雷斯大学的研究者通过OpenAI的API开发了Fairyland AI,旨在为儿童生成有趣的、有教育意义的、符合年龄和文化背景的童话故事,同时为Gen AI、DALL·E 3等图像生成工具提供富有想象力的提示词,搭配图片提升故事体验。11 Labs推出ReaderRap应用和Iconic Voices名人声音合集,可以用模仿名人声音的AI感情丰富地阅读新闻、PDF文件、电子书等手机中不同格式的数字文本。浙江大学的研究者推出Bias Alert工具,旨在检测大模型生成的文本内容中的社会偏见。Bias Alert融合外在的人类知识和内在的推理能力,能够可靠地检测出偏见,表现显著优于GPT-4 as a Judge等方法,有助于在多样的场景中弱化偏见内容。香港大学的研究者面向开放世界的任务规划,推出语言增强的符号规划器LASP,Language Augmented Symbolic Planner,如何预训练大模型让传统的符号规划器能够以有限的领域知识在开放世界环境中运行。在出现执行错误的时候,LASP会用大模型观察诊断错误原因,通过与环境的互动打造完成特定任务所需要的知识库。相较Inner Monologue等语言驱动的规划方法,LASP的表现更好。Google DeepMind的研究者面向多模态指令导航,Instruction Navigation,推出Mobility VLA视觉语言行动导航策略,将视觉语言模型的环境理解能力和常识推理能力与基于拓扑图的底层导航策略结合起来,根据当前状态和环境信息实时地规划和生成机器人动作。在真实环境中的评估发现,Mobility VLA能够以相当高的成功率解决此前难解的多模态指令问题,比如拿着一个收纳箱问他,我应该把这个放到哪里。Ego4D数据集专注于第一人称视角的四维视频,4D是指3D加时间这个加一面值。Ego4D用于研究和开发能够理解和预测人类行为的人工智能模型。在此基础上,谷歌等研究者面向智能助手Intelligent Assistant推出Parse Ego4D数据集,不只提供视频的标注,而是聚焦动作建议的标注,是Personal Action Recommendation Annotations,帮助研究者和开发者为增强现实和虚拟现实系统创建动作推荐系统。中国科学技术大学等研究者推出Motion Clone动作克隆框架,无需训练即可将参考视频中的动作克隆到文本生成的视频中。实验证明,Motion Clone在全局相机运动和局部物体运动方面表现优秀,具备很好的动作一致性、指令一致性和时间一致性。这里再次推荐我们7月初介绍过的这本书,快速部署大模型LLM策略与实践。这本书强调实践,旨在帮助读者学习使用、构建和部署大模型来解决实际问题,比如用自己的数据集对大模型进行微调,构建多模态视觉问答系统,以及根据特定需求改进开源模型等等。链接请参考评论区置顶。回到周报,投资公司Manlo Ventures与Anthropic联合启动1亿美元资金Anthology Fund,面向早期阶段的AI初创公司提供至少10万美元资金和建议支持的同时,还有2.5万美元新额度可以使用Anthropic最先进的模型。生成式AI平台Vector完成2500万美元A轮融资,相较Next等参头,同时公司推出面向RAG应用的微调大模型Markingbird,能够减少AI幻觉,提升输出质量,尤其适合要求准确度、安全性和可解释能力的医疗、法律、金融、制造等领域。医疗决策软件公司Regard完成6100万美元B轮融资,估值3.5亿美元。Regard开发的AI Copilot能够帮助医生处理文件流程,辅助诊断医疗条件,公司已经与若干大型医疗系统达成合作。声音认证和安全公司Pandrop完成1亿美元融资,公司主要利用AI帮助企业组织的客服中心大规模识别虚假电话与真实的客户电话。目前共分析53亿多通电话,检测出1.04亿虚假电话,避免了20亿美元的欺诈损失。这期节目就到这里,前面提到的论文链接请参考视频下方的简介部分。Thanks for listening!