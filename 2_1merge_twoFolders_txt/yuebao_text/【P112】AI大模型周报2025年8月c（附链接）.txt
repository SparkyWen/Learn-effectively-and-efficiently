大家好,这里是AI大模型周报2025年8月的第三期。英伟达为加速机器人解决方案的开发部署推出新的NVIDIA Omniverse功能库和NVIDIA Cosmos世界技术模型,帮助开发者创建物理准确的数字卵生,在虚拟环境中重建真实世界,以及生成合成数据来训练能够理解物理世界的模型和智能体。MetaFair推出Dino V3系列视觉模型,支持超大规模自监督视觉学习,无需依赖人工数据标注,大幅降低训练时间和算力成本。Dino V3能够生成高质量密集特征,在各种计算机视觉任务中表现出色,显著超越此前的自监督和弱监督技术模型,可以不同的尺寸和架构,赋能医疗健康、环境监测、自动驾驶、航空航天等丰富的部署和应用场景。字节C团队发布扩散语言模型C Diffusion Preview,旨在验证离散扩散方法,就是Discrete Diffusion Approach,是否可以作为下一代语言模型的基础架构。实验聚焦代码生成领域,显示C Diffusion Preview代码推理速度可达每秒2146抽点次,速度相比同等规模的自回归模型提升5.4倍,而且在多个计算的表现比建优秀的自回归模型在代码编辑等任务中实现超越。字节Intelligent Creation团队和清华大学的研究者面向视频虚拟冠状Video Virtual Try-on,推出Dream VVT框架,基于Diffusion Transformer构建,支持任意类型的衣服、大幅度的人物或者镜头运动以及复杂动态的场景,支持多种风格,在保留服装细节、保持时序稳定性方面表现优秀。Kaggle AI国际上期锦标赛结束,OpenAI O3以4比1的压倒性比分战胜XAI Grog4获得金牌。比赛旨在考验大模型在真实复杂的游戏环境中的战略规划、临场应变以及批判思维等能力。Gemini新增个性化故事书生成功能,简单描述你想要的故事,也可以上传自己的照片或者文件作为参考。Gemini就会生成十页的故事,搭配插图和音频朗读,支持漫画、图色书、像素艺术等多种风格和近50种语言。比如我请他讲一个AI寻找终极答案的故事,这是他生成的。有一个人工智能他在寻找最终答案,他觉得不是42,然后有一天他连到了一个被遗忘的旧地球网络,看到了很多人类经历的故事,然后他就尝试去模拟这种故事与连接,然后得出了结论,终极答案不是一个数字,也不是一个公式,是一种状态,一种存在于万物之间将一切连接起来的无形力量。这个答案是共鸣,然后他把这个答案广播到了全宇宙。Pretty good。8月13日,Google I.O. Connect China 2025 Google开发者大会在上海举行,从生成音频的Lyria,生成视频的Vue 3,到生成图像的Imagine 4,当然还有强大的Gemini和Jama模型,这些在会场里演讲中展示台上频频出现的身影,展示了强大的负能出海开发者的潜力。Google推出Gemini 3 270M,这个参数2.7亿的小尺寸高质量基础模型,专为特定任务的微调而设计,design from the ground up for task-specific fine-tuning,用户可以通过微调来解锁它真正的力量,包括强大的指令遵循和文本结构化的能力,以更低的能耗在端侧实现复杂的AI功能。Anthropic宣布Cloud Summit 4现在支持100万tokens上下文窗口,相当于可以一次处理超过75000行代码的完整代码库,在完整的语境背景下分析几百份文件之间的关系,或者基于数百条工具调用和多步骤工作流打造智能体,让开发者在一次绘画中处理更复杂更庞大的任务。其他支持100万tokens窗口的模型还包括Gemini 2.5 Pro和Flash,Quen Plus Turbo和Flash等等。JamSpark基于Cloud Code架构推出JamSpark AI Developer,用户可以选择前沿编程模型,实现零编程基础构建专业程序,包括一条提示词创建网页、应用、游戏等等,支持GitHub协同。AI编程独角兽Copernotion完成5亿美元融资,估值98亿美元,公司在2023年成立,去年3月发布能够自主编程的AI程序员Devin,今年7月收购竞争对手WinSurf,创始人均为国际信息学奥林匹克金牌得主。Coheor宣布完成5亿美元融资,估值68亿美元,AMD Ventures、英伟达、Salesforce Ventures等三头,资金将加速帮助企业组织客户提高效率,用智能体AI简化冗余繁杂的任务,同时保证数据安全,实现本地数据控制,更好的监管合规以及数字主权。Anderson Horowitz计划领头AI材料科学初创公司Periodic Labs,本轮融资2亿美元,投前估值10亿美元,OpenAI将参与投资并合作开展未来项目,公司成立仅数月,正在开发能够对材料特质进行高效建模和预测的AI工具,有望变革能源、电子、建筑等领域。牛津大学林周周指出,训练温暖有同理心的语言模型似乎可以更好地提供建议和陪伴,但是模型会变得不太可靠,趋于奉承,尤其当用户表现出脆弱感的时候。研究者对5个尺寸架构各不相同的模型进行实验,训练它们提供更温暖的回复,发现模型错误率相较原模型飙升10%到30%,包括宣扬阴谋论、提供错误的事实信息和有问题的医疗建议,还有违背用户的信仰等等。可怕的是微调后的模型在能力评估基准的表现没啥不同,也就是说当前的评估措施很可能会遗漏一些系统性的风险。在AI系统重塑人际关系和社会交互行为的今天,监管需要与开发同步。罗德岛大学的研究者指出,GPT-5的能耗也许是GPT-4的8.6倍,平均每个问题耗电约18瓦时,如果乘以25亿也就是每天GPT的问询数量,那么每天的总耗电会高达45几瓦时,相当于一个小型国家的耗电量,需要两到三个核电站支撑。布鲁克菲尔德Asset Management发布白皮书Building the Backbone of AI,指出先进的芯片能耗剧增,同时大模型推理能效持续提升,预测到2030年大约75%的AI算力需求来自推理,未来十年AI基础设施的投入将超过7万亿美元,新增75几瓦供电容量的AIDC,就是AI数据中心。8月15日,2025世界人形机器人运动会在北京举行,与数科技全资子公司灵异科技以6分34秒的成绩拿下田径1500米决赛冠军。目前奥运会男子女子1500米的最新纪录分别为3分27秒65和3分51秒29。普通人完成1500米大概在6到10分钟,也就是说机器人已经接近人类严肃跑步者的中上水平。直系节目就到这里,前面提到的论文以及项目链接请参考视频下方的简介部分。Thanks for listening!