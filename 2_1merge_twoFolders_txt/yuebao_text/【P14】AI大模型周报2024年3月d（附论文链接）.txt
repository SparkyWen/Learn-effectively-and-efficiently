大家好,这里是AI大模型周报2023年3月的第四季。英伟达发布Blackwell平台意味着近八年来AI算力增长了一千倍。采用Blackwell架构的GB200系列算胶去年3月推出的H100可以为大语言模型推理负载提供30倍的性能提升,同时成本和能耗降到25分之一。基于NVIDIA CUDA平台,英伟达启动生成式AI云原生微服务NEM,就是NEMO Microservices,企业可在自己的平台创建部署定制化应用。NEM专门面向20多个人际AI模型的优化推理,包括来自Google、Hugging Face、Meta、Microsoft、Mistral AI、Stability AI等的开源模型。另外,英伟达推出机器人项目Groot,这个通用基础模型支持多模态指令,能够让人形机器人通过对人类演示的模仿学习,通过机器人模拟平台NVIDIA ASEC Lab的增强学习,甚至根据视频数据来掌握技能执行任务。马斯克XAI宣布开源3141参数的混合专家模型Grok1,以及模型的全重和网络架构,这是当前参数量最大的开源大模型。经过四个月的研发,Grok1在若干基准测试中超过GPT-3.5和Infection1的模型,将作为Grok背后的引擎处理自然语言任务。腾讯发布自研游戏AI引擎GNEX,将为游戏全生命周期提供丰富的AI解决方案。GNEX借助生成式AI技术面向AI NPC、场景制作、内容生成等场景,提供包括2D图像、3D城市、剧情、关卡、音乐、对话等多样的AI聚集能力,帮助开发者提升高质量内容的生成效率,同时将角色AI技术用于游戏研发测试、模拟玩法等场景,加速游戏创新迭代。苹果研究者推出多模态大模型系列MM1,参数最高300亿,由密集模型和混合专家变体组成。在上下文预测、多图像和思维链推理等方面表现亮眼。自动驾驶AI公司Wabi推出基础模型Copilot4D,能够在3D空间以及时间这个第四维度进行明晰的推理。利用LIDAR Tokenizer,也就是雷达标记器,将连续的传感器数据转化成离散的标记,就是转化成Discrete Tokens。像大语言模型预测句子中的下一个单词那样,预测机器下一步如何观察世界,以及具身AI代理如何影响这个世界。Copilot4D能够在虚拟或现实的动态世界中学习各类交互能力,应用场景包括自动驾驶汽车、机器人等领域。3月18日,月之暗面宣布其对话式AI助手产品Kimi现在已经支持200万字的无损上下文输入。在去年10月发布的时候,Kimi可以支持的上下文输入长度是20万字,就是去年10月发布时候的10倍。目前,Kimi智能助手已经上线了网页版、安卓版、iOS、小程序应用。SimilarWeb数据显示,Kimi智能助手网页版今年2月的访问量为291.9万,同比上月增长约105%。清华大学等研究者面向开放世界的机器人控制推出COPPA框架,用视觉语言模型,也就是VLMs,嵌入常识知识,生成6 Degrees of Freedom,也就是6个自由度的末端系动作。和BugsPoser比较发现,COPPA的场景理解能力更强,比如抓取花束,COPPA会抓取根茎而不是花朵的部分,或者锤钉子,COPPA会调整锤子的角度而不是单纯地将锤子的位置安排在钉子的上方。此外,它还可以无缝融合现有的机器人规划算法,来完成复杂的长期任务。哥伦比亚大学和西北大学的研究者面向无人机的感知和反应能力推出RASP平台。这是一个模块化和重组的传感驱动平台,能够让无人机在25秒之内自动切换传感器和驱动器,进而快速适应各类任务。同时,团队基于大语言模型和视觉语言模型的最新进展,利用RASP推出个人助手系统,覆盖家庭、办公室、实验室等室内场景,包括定位导航,比如询问哪里坐着最暖和,我的手机在哪里,可以监测事物的状态和发展,比如问它水龙头关了吗,请监测化学实验防止溶液溢出,它还可以运送物品,比如把零食拿给我的宠物等等。哈佛Hies Medical Institute的神经科学研究机构Genedia Research Campus以及Philadelphia Robotics,Google DeepMind等的研究者打造了一个果蝇模型,能够像真实的果蝇一样行走、飞行,包括用眼睛控制和引导飞行。研究者认为动物的身体决定着神经系统产出行为的方式,对成年雌果蝇创建了细致入微的3D模型,然后模拟它与环境的互动,通过模仿学习训练神经网络控制器,生成真实的运动。深室科技和北京科学智能研究院的研究者面向科学文献分析任务,推出UniSmart,它的全称是Universal Science Multimodal Analysis and Research Transformer,旨在深度理解多模态科学文献,包括文本、分词、结构图、化学反应图等等,还可以扩展到专利精选检测等实用场景。这次的大学的研究者针对网络虚假信息和阴谋论的问题,推出开源大模型Conspimo LLM,考虑虚假信息与人类情绪情感的关系,如何影响情感的信息,能够执行与阴谋论相关的多种任务,包括检测阴谋论的内容、进行分类以及检测相关讨论,比如支持阴谋论的言论。华东师范大学的研究者针对抑郁诊断型对话,提出将精神状态追踪,就是Psychological State Tracking,融合到大模型中,捕捉患者在对话中不断变化的情绪和挣扎,对抑郁诊断型对话进行有效的引导。提斯堡大学的研究者聚焦家庭看护领域,主要面向Old Timer患者的看护者,开发看护语言模型COM,利用71参数的Lama2和Falcon作为基础模型,采用检索增强生成框架,基于网络上各类相关文件整理专门的知识库,为家庭看护者提供支持。赛理大学和Meta Reality Labs的研究者面向手语翻译,推出Spider Plus GPT方案,结合手语检测器和SignSpotter和ChatGPT的自然语言生成能力,旨在更好地基于手语视频生成连贯流畅的语言语句。南京大学和腾讯研究者推出图像编辑框架StableDrag,采用判别式点跟踪方法精确定位更新的操纵点,保证编辑图像的稳定性。在运动监督方面,利用基于置信的潜在增强策略来保证优化的潜在变量能够在所有操纵步骤中保持高质量。与DragCan、DragDiffusion和FreeDrag的比较发现,StableDrag的编辑质量较高。比如这个狮子的头,FreeDrag都变窄了,StableDrag就比较正常。哥伦比亚大学团队开源类Sora架构的视频生成模型OpenSora 1.0,涵盖整个训练流程,包括模型架构设计、数据预处理、训练复现方案等等。虽然仍有诸多不足,但显著降低了Sora复现的技术门槛,提升视频时长、分辨率、内容等多个维度的质量。斯坦福大学研究者面向长视频理解推出Video Agent代理系统,利用大语言模型以迭代优化的方式识别和组织关键信息来回答问题,同时将视觉语言技术模型作为工具来翻译和检索视觉信息。基于EgoSchema和NextKeyway的评估发现,Video Agent平均只需要8帧画面就能实现54.1%到71.3%的零样本精准度,说明基于代理的方法有望负能长视频理解。伦敦大学玛丽皇后学院的研究者面向音频生成与编辑推出WaveCraft,利用大模型的上下文学习能力将用户的指令分解成若干次任务,由专家模型逐一协作处理,实现根据细节和逻辑的音频创作。WaveCraft支持对话交互,可以基于输入的音频按照复杂的指令辅助编辑和创作。电气和自动化技术厂商ABB宣布将人工智能嵌入全线业务,100多个AI项目正在推进中。今年初ABB收购瑞士初创公司7Sense,并且收购了研发工程公司MeshMind的大部分股份,扩大在人工智能、工业物联网和机器视觉领域的研发能力。聚焦医疗健康大模型的Hippocratic AI完成5300万美元A轮融资,估值5亿美元,同时公司的第一款产品进入第三阶段安全测试,