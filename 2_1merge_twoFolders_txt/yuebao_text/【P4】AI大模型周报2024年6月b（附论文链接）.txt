大家好,这里是AI大模型周报2024年6月的第二期,Stability AI宣布推出开放模型Stable Audio Open,能够基于简单的文本提示生成47秒时长的高质量音频。Stable Audio Open适合创建乐器片段、环境音、模拟录音等音频样本,支持用户用自定义音频数据对模型进行微调。佐治亚理工学院研究者面向视频总结提出系列大语言视觉模型Sherlock Holmes,聚焦视频的镜头和镜头之间的细力度与意义信息,让大语言视觉模型从理解单个画面到能够理解画面序列。研究发现Sherlock Holmes能够以更小更高效的模型更好地完成视频注释和总结任务。微软研究者开发AI气象基础模型Aurora,参数13亿,基于100多万个小时的各类天气和气候模拟进行训练,能够从海量气象数据中提取有价值的洞见,帮助人们预测气象演化,减轻极端天气可能造成的消极影响。GDMind推出生物分子结构预测模型AlphaFold 3之后,阿里云飞天实验室发布生物大模型LucaOne,基于来自169861个物种的DNA、RNA和蛋白质数据,综合学习遗传和蛋白质语言,通过少样本学习LucaOne能够有效学习分子生物学的中心法则,表现超过同类模型。中国电信与昆仑万维等联合发布新城Math平台,就是Model as a Service模型及服务,为行业客户提供端到端大模型解决方案,满足多元算力调度、大模型选配以及场景创新等需求。6月6日,英伟达市值突破3万亿美元,超过苹果排名世界第二,今年股价累计涨幅147%。目前BlackWall芯片已经投入生产,相较2016年的Pascal算力提升1000倍,预计2026年推出下一代AI平台Ruben。AMD在Computex大会上介绍了全新Zen 5架构、桌面端、Ryzen 9000 CPU、AI PC芯片、数据中心芯片和CPU。相较Zen 4,Zen 5的IPC,也就是Instruction Per Clock Cycle,在每个时钟周期内处理器能够执行的指令数量提升了大约16%。Google DeepMind的研究者就大模型的创意知识能力进行研究。研究者对20位使用AI辅助创作的专业喜剧演员进行采访,受访者指出,目前安全顾虑和指令微调的大模型所使用的审查策略会强化霸权观点,抹除少数群体的观点。多数参与者认为大模型生成的喜剧套路无聊而且带有偏见,并不能很好地支持创作。要创建能够更好满足艺术家需求的AI工具,不该一概而论,而应该强调基于社区群体的价值对接和数据所有权。要将多个基于不同模态训练的生成式基础模型融合起来实现一加一大于二,主要面临两大挑战。一是对齐的数据,aligned data,就是用不同模态表述了相同含义的概念。另一个挑战则是在跨领域的生成式任务中有效地利用单模态表征,同时不影响原始单模态能力。为此,Google DeepMind的研究者推出Zipper多塔解码器架构,利用交叉注意力从独立于训练的单模态解码器中灵活地组合多模态生成模型。在融合语音和文本模态的实验中,Zipper在对基文本语音数据有限的情况下表现优秀。此外,还可以通过冻结相应的模态,by freezing the corresponding model tower,来有选择地保持单模态生成能力。北京大学的研究者推出DriveWorld基于世界模型的自动驾驶4D表征学习框架,纳入自动驾驶场景理解的时间特征,temporal characteristics,这个第四维度,基于多角度驾驶视频进行预训练。实验显示DriveWorld在各种自动驾驶任务中表现优秀,使用OpenScene数据集预训练,DriveWorld的3D物体识别MAP,也就是Mean Average Precision,在不同预知下的平均精度提高了7.5%,实时创建环境地图的IOU,也就是Intersection over Union,交并比提升近3%,多目标跟踪的平均精准度提升超过5%,等等。普渡大学的研究者推出训练框架SaySelf,能够让大语言模型给出更加精确的细力度自信评估,Confidence Estimates,也就是模型对自己给出的答案有多自信的一个量化指标。此外,SaySelf还可以引导大模型生成粉丝,清楚地识别参数知识中的空白并解释自己的不确定性。实验显示SaySelf能够有效减少执行度校准误差,同时保证执行特定任务的表现。亚利桑那州立大学的研究者推出LLM Modular框架,能够将大模型更好地用在不同的规划和推理任务中。基于此,研究者聚焦旅行规划,Travel Planning,这个涉及交通、住宿、活动等选择,并且选择之间相互依赖需要高度逻辑推理的复杂领域。发现基于LLM Modular框架的旅行规划任务表现更加,是GPT-4 Turbo基线性能的4.68倍,更加GPT-3.5 Turbo的通过率从0提升到5%。摩纳什大学的研究者面向文学翻译推出多代理框架,Trans Agents,聚焦多个代理的能力,助力文学作品翻译的难题。为了评估系统的有效性,研究者提出两个评估策略,分别是MHP,Modeling World Human Preference,从目标语言的角度评估翻译质量以及BLP,Bilingual LLM Preference,用大模型直接比较翻译和原文。虽然仍有局限,但相较人工译文,人类评估员和大模型都更信赖Trans Agents的译文,尤其是需要专门领域知识的翻译。Meta的Fundamental AI Research Fair团队提出新的未知编码方法COPE,全称Contextual Positioning Coding,上下文未知编码,允许模型根据上下文条件灵活调整编码位置,精确定位特定的单词或句子。COPE能够拓宽模型在自然语言处理领域的应用范围,在交替任务Flip-Flop,选择性复制任务Selective Copy,记数任务Counting,语言建模还有编码建模等任务的表现优秀。油路机器人获得超1亿元融资,这家巨生智能公司专注研发机器人通用大脑,由简阿里大模型机器人实验室负责人陈俊波博士在2023年创建。2023年,油路机器人联合阿里云通一千万发布巨生智能大模型LPLM,适用轮式、复合式、人形等全类型机器人的通用巨生大脑。今年3月发布基于LPLM的通用巨生大脑产品Master 2000,两个月达成超千万订单收入。AI视频生成初创公司PickUp完成8000万美元融资,估值达到4.7亿美元,将继续训练公司自主研发的基础模型并改进视频编辑工具的功能。今年4月联合清华大学发布视频大模型V2的生术科技完成数亿美元Pre-A轮融资。下一步将持续迭代优化自研大模型,加速产品开发与市场拓展。The Wall Street Journal报道,Sam Altman积极风投基金投资超过400家公司,使股价值超过28亿美元。作为市值860亿美元的OpenAI的CEO,年薪6.5万美元的Altman并不持有OpenAI的股份。而根据Bloomberg Billionaires Index的数据,其净资产已经超过20亿美元。这期节目就到这里,前面提到的论文链接请参考视频下方的简介部分。Thanks for listening!